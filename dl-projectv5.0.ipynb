{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-11-22T08:31:00.401193Z",
     "iopub.status.busy": "2024-11-22T08:31:00.400813Z",
     "iopub.status.idle": "2024-11-22T08:31:40.783944Z",
     "shell.execute_reply": "2024-11-22T08:31:40.782296Z",
     "shell.execute_reply.started": "2024-11-22T08:31:00.401164Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "keras-cv 0.9.0 requires keras-core, which is not installed.\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\n",
      "jupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "momepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "osmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "pointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "spaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "spopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --quiet langchain langchain-community langchain-openai langchain-experimental neo4j langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:31:40.786918Z",
     "iopub.status.busy": "2024-11-22T08:31:40.786463Z",
     "iopub.status.idle": "2024-11-22T08:31:44.170559Z",
     "shell.execute_reply": "2024-11-22T08:31:44.169369Z",
     "shell.execute_reply.started": "2024-11-22T08:31:40.786875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "import os\n",
    "os.environ[\"NEO4J_URI\"] = \"neo4j+s://80e9be90.databases.neo4j.io\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"...\"\n",
    "\n",
    "graph = Neo4jGraph(refresh_schema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:31:44.173218Z",
     "iopub.status.busy": "2024-11-22T08:31:44.172569Z",
     "iopub.status.idle": "2024-11-22T08:31:44.178343Z",
     "shell.execute_reply": "2024-11-22T08:31:44.177162Z",
     "shell.execute_reply.started": "2024-11-22T08:31:44.173177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Generation of MAIN Acedamic Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T03:19:39.294263Z",
     "iopub.status.busy": "2024-11-22T03:19:39.293879Z",
     "iopub.status.idle": "2024-11-22T03:19:39.870314Z",
     "shell.execute_reply": "2024-11-22T03:19:39.868939Z",
     "shell.execute_reply.started": "2024-11-22T03:19:39.294236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_groq import ChatGroq\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0, model_name=\"gpt-4-turbo\")\n",
    "llm = ChatGroq(model=\"llama-3.1-70b-versatile\", temperature=0)\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T17:08:48.246829Z",
     "iopub.status.busy": "2024-11-21T17:08:48.246516Z",
     "iopub.status.idle": "2024-11-21T17:09:09.623749Z",
     "shell.execute_reply": "2024-11-21T17:09:09.622571Z",
     "shell.execute_reply.started": "2024-11-21T17:08:48.246802Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Mathematics', type='Field', properties={}), Node(id='Linear Algebra', type='Subset', properties={}), Node(id='Calculus', type='Subset', properties={}), Node(id='Probability', type='Subset', properties={}), Node(id='Statistics', type='Subset', properties={}), Node(id='Discrete Mathematics', type='Subset', properties={}), Node(id='Graph Theory', type='Subset', properties={}), Node(id='Number Theory', type='Subset', properties={}), Node(id='Combinatorics', type='Subset', properties={}), Node(id='Programming Languages', type='Tools', properties={}), Node(id='Computer Science', type='Field', properties={}), Node(id='Object-Oriented Programming', type='Paradigm', properties={}), Node(id='Functional Programming', type='Paradigm', properties={}), Node(id='Procedural Programming', type='Paradigm', properties={}), Node(id='Java', type='Language', properties={}), Node(id='Python', type='Language', properties={}), Node(id='C++', type='Language', properties={}), Node(id='Javascript', type='Language', properties={}), Node(id='Assembly Language', type='Language', properties={}), Node(id='Database Systems', type='Component', properties={}), Node(id='Sql', type='Language', properties={}), Node(id='Nosql', type='Type', properties={}), Node(id='Mongodb', type='Database', properties={}), Node(id='Postgresql', type='Database', properties={}), Node(id='Database Design', type='Skill', properties={}), Node(id='Data Modeling', type='Part', properties={}), Node(id='Normalization', type='Part', properties={}), Node(id='Query Optimization', type='Part', properties={}), Node(id='Artificial Intelligence', type='Field', properties={}), Node(id='Machine Learning', type='Subset', properties={}), Node(id='Deep Learning', type='Subset', properties={}), Node(id='Neural Networks', type='Part', properties={}), Node(id='Natural Language Processing', type='Part', properties={}), Node(id='Computer Vision', type='Part', properties={}), Node(id='Reinforcement Learning', type='Part', properties={}), Node(id='Supervised Learning', type='Type', properties={}), Node(id='Unsupervised Learning', type='Type', properties={}), Node(id='Software Engineering', type='Field', properties={}), Node(id='Software Development Life Cycle', type='Part', properties={}), Node(id='Version Control', type='Part', properties={}), Node(id='Git', type='Tool', properties={}), Node(id='Testing', type='Part', properties={}), Node(id='Unit Testing', type='Type', properties={}), Node(id='Integration Testing', type='Type', properties={}), Node(id='Agile Development', type='Methodology', properties={}), Node(id='Devops', type='Part', properties={}), Node(id='Operating Systems', type='Component', properties={}), Node(id='Computer Architecture', type='Component', properties={}), Node(id='Memory Management', type='Part', properties={}), Node(id='Process Management', type='Part', properties={}), Node(id='File Systems', type='Part', properties={}), Node(id='Networking', type='Component', properties={}), Node(id='Tcp/Ip', type='Protocol', properties={}), Node(id='Internet Protocols', type='Part', properties={}), Node(id='Distributed Systems', type='Systems', properties={}), Node(id='Cybersecurity', type='Field', properties={}), Node(id='Cryptography', type='Part', properties={}), Node(id='Network Security', type='Part', properties={}), Node(id='Information Security', type='Part', properties={}), Node(id='Encryption', type='Part', properties={}), Node(id='Authentication', type='Part', properties={}), Node(id='Authorization', type='Part', properties={}), Node(id='Penetration Testing', type='Part', properties={}), Node(id='Data Science', type='Field', properties={}), Node(id='Data Analysis', type='Part', properties={}), Node(id='Data Mining', type='Part', properties={}), Node(id='Big Data', type='Related', properties={}), Node(id='Data Visualization', type='Part', properties={}), Node(id='Statistical Analysis', type='Part', properties={}), Node(id='Predictive Analytics', type='Part', properties={}), Node(id='Feature Engineering', type='Part', properties={}), Node(id='Web Development', type='Application', properties={}), Node(id='Frontend Development', type='Part', properties={}), Node(id='Backend Development', type='Part', properties={}), Node(id='Html', type='Used', properties={}), Node(id='Css', type='Used', properties={}), Node(id='Javascript Frameworks', type='Used', properties={}), Node(id='Node.Js', type='Used', properties={}), Node(id='Restful Apis', type='Part', properties={}), Node(id='Http', type='Protocol', properties={}), Node(id='Tensorflow', type='Used', properties={}), Node(id='Pytorch', type='Used', properties={}), Node(id='Kubernetes', type='Used', properties={}), Node(id='Docker', type='Used', properties={}), Node(id='Aws', type='Platform', properties={}), Node(id='Azure', type='Platform', properties={}), Node(id='Visual Studio Code', type='Ide', properties={}), Node(id='Eclipse', type='Ide', properties={}), Node(id='Linux', type='Operating system', properties={}), Node(id='Design Patterns', type='Part', properties={}), Node(id='Microservices Architecture', type='Architecture', properties={}), Node(id='Mvc Pattern', type='Pattern', properties={}), Node(id='Clean Architecture', type='Principle', properties={}), Node(id='Solid Principles', type='Principles', properties={}), Node(id='Api Design', type='Part', properties={}), Node(id='System Design', type='Part', properties={}), Node(id='Cloud Architecture', type='Part', properties={})]\n",
      "Relationships:[Relationship(source=Node(id='Linear Algebra', type='Subset', properties={}), target=Node(id='Mathematics', type='Field', properties={}), type='SUBSET', properties={}), Relationship(source=Node(id='Calculus', type='Subset', properties={}), target=Node(id='Mathematics', type='Field', properties={}), type='SUBSET', properties={}), Relationship(source=Node(id='Probability', type='Subset', properties={}), target=Node(id='Mathematics', type='Field', properties={}), type='SUBSET', properties={}), Relationship(source=Node(id='Statistics', type='Subset', properties={}), target=Node(id='Mathematics', type='Field', properties={}), type='SUBSET', properties={}), Relationship(source=Node(id='Discrete Mathematics', type='Subset', properties={}), target=Node(id='Mathematics', type='Field', properties={}), type='SUBSET', properties={}), Relationship(source=Node(id='Graph Theory', type='Subset', properties={}), target=Node(id='Discrete Mathematics', type='Subset', properties={}), type='SUBSET', properties={}), Relationship(source=Node(id='Number Theory', type='Subset', properties={}), target=Node(id='Discrete Mathematics', type='Subset', properties={}), type='SUBSET', properties={}), Relationship(source=Node(id='Combinatorics', type='Subset', properties={}), target=Node(id='Discrete Mathematics', type='Subset', properties={}), type='SUBSET', properties={}), Relationship(source=Node(id='Programming Languages', type='Tools', properties={}), target=Node(id='Computer Science', type='Field', properties={}), type='TOOLS', properties={}), Relationship(source=Node(id='Object-Oriented Programming', type='Paradigm', properties={}), target=Node(id='Programming Languages', type='Tools', properties={}), type='PARADIGM', properties={}), Relationship(source=Node(id='Functional Programming', type='Paradigm', properties={}), target=Node(id='Programming Languages', type='Tools', properties={}), type='PARADIGM', properties={}), Relationship(source=Node(id='Procedural Programming', type='Paradigm', properties={}), target=Node(id='Programming Languages', type='Tools', properties={}), type='PARADIGM', properties={}), Relationship(source=Node(id='Java', type='Language', properties={}), target=Node(id='Object-Oriented Programming', type='Paradigm', properties={}), type='LANGUAGE', properties={}), Relationship(source=Node(id='Python', type='Language', properties={}), target=Node(id='Programming Languages', type='Tools', properties={}), type='LANGUAGE', properties={}), Relationship(source=Node(id='C++', type='Language', properties={}), target=Node(id='Programming Languages', type='Tools', properties={}), type='LANGUAGE', properties={}), Relationship(source=Node(id='Javascript', type='Language', properties={}), target=Node(id='Programming Languages', type='Tools', properties={}), type='LANGUAGE', properties={}), Relationship(source=Node(id='Assembly Language', type='Language', properties={}), target=Node(id='Programming Languages', type='Tools', properties={}), type='LANGUAGE', properties={}), Relationship(source=Node(id='Database Systems', type='Component', properties={}), target=Node(id='Computer Science', type='Field', properties={}), type='COMPONENT', properties={}), Relationship(source=Node(id='Sql', type='Language', properties={}), target=Node(id='Database Systems', type='Component', properties={}), type='LANGUAGE', properties={}), Relationship(source=Node(id='Nosql', type='Type', properties={}), target=Node(id='Database Systems', type='Component', properties={}), type='TYPE', properties={}), Relationship(source=Node(id='Mongodb', type='Database', properties={}), target=Node(id='Nosql', type='Type', properties={}), type='DATABASE', properties={}), Relationship(source=Node(id='Postgresql', type='Database', properties={}), target=Node(id='Sql', type='Language', properties={}), type='DATABASE', properties={}), Relationship(source=Node(id='Database Design', type='Skill', properties={}), target=Node(id='Database Systems', type='Component', properties={}), type='SKILL', properties={}), Relationship(source=Node(id='Data Modeling', type='Part', properties={}), target=Node(id='Database Design', type='Skill', properties={}), type='PART', properties={}), Relationship(source=Node(id='Normalization', type='Part', properties={}), target=Node(id='Database Design', type='Skill', properties={}), type='PART', properties={}), Relationship(source=Node(id='Query Optimization', type='Part', properties={}), target=Node(id='Database Systems', type='Component', properties={}), type='PART', properties={}), Relationship(source=Node(id='Artificial Intelligence', type='Field', properties={}), target=Node(id='Computer Science', type='Field', properties={}), type='FIELD', properties={}), Relationship(source=Node(id='Machine Learning', type='Subset', properties={}), target=Node(id='Artificial Intelligence', type='Field', properties={}), type='SUBSET', properties={}), Relationship(source=Node(id='Deep Learning', type='Subset', properties={}), target=Node(id='Machine Learning', type='Subset', properties={}), type='SUBSET', properties={}), Relationship(source=Node(id='Neural Networks', type='Part', properties={}), target=Node(id='Deep Learning', type='Subset', properties={}), type='PART', properties={}), Relationship(source=Node(id='Natural Language Processing', type='Part', properties={}), target=Node(id='Artificial Intelligence', type='Field', properties={}), type='PART', properties={}), Relationship(source=Node(id='Computer Vision', type='Part', properties={}), target=Node(id='Artificial Intelligence', type='Field', properties={}), type='PART', properties={}), Relationship(source=Node(id='Reinforcement Learning', type='Part', properties={}), target=Node(id='Machine Learning', type='Subset', properties={}), type='PART', properties={}), Relationship(source=Node(id='Supervised Learning', type='Type', properties={}), target=Node(id='Machine Learning', type='Subset', properties={}), type='TYPE', properties={}), Relationship(source=Node(id='Unsupervised Learning', type='Type', properties={}), target=Node(id='Machine Learning', type='Subset', properties={}), type='TYPE', properties={}), Relationship(source=Node(id='Software Engineering', type='Field', properties={}), target=Node(id='Computer Science', type='Field', properties={}), type='FIELD', properties={}), Relationship(source=Node(id='Software Development Life Cycle', type='Part', properties={}), target=Node(id='Software Engineering', type='Field', properties={}), type='PART', properties={}), Relationship(source=Node(id='Version Control', type='Part', properties={}), target=Node(id='Software Engineering', type='Field', properties={}), type='PART', properties={}), Relationship(source=Node(id='Git', type='Tool', properties={}), target=Node(id='Version Control', type='Part', properties={}), type='TOOL', properties={}), Relationship(source=Node(id='Testing', type='Part', properties={}), target=Node(id='Software Engineering', type='Field', properties={}), type='PART', properties={}), Relationship(source=Node(id='Unit Testing', type='Type', properties={}), target=Node(id='Testing', type='Part', properties={}), type='TYPE', properties={}), Relationship(source=Node(id='Integration Testing', type='Type', properties={}), target=Node(id='Testing', type='Part', properties={}), type='TYPE', properties={}), Relationship(source=Node(id='Agile Development', type='Methodology', properties={}), target=Node(id='Software Engineering', type='Field', properties={}), type='METHODOLOGY', properties={}), Relationship(source=Node(id='Devops', type='Part', properties={}), target=Node(id='Software Engineering', type='Field', properties={}), type='PART', properties={}), Relationship(source=Node(id='Operating Systems', type='Component', properties={}), target=Node(id='Computer Science', type='Field', properties={}), type='COMPONENT', properties={}), Relationship(source=Node(id='Computer Architecture', type='Component', properties={}), target=Node(id='Computer Science', type='Field', properties={}), type='COMPONENT', properties={}), Relationship(source=Node(id='Memory Management', type='Part', properties={}), target=Node(id='Operating Systems', type='Component', properties={}), type='PART', properties={}), Relationship(source=Node(id='Process Management', type='Part', properties={}), target=Node(id='Operating Systems', type='Component', properties={}), type='PART', properties={}), Relationship(source=Node(id='File Systems', type='Part', properties={}), target=Node(id='Operating Systems', type='Component', properties={}), type='PART', properties={}), Relationship(source=Node(id='Networking', type='Component', properties={}), target=Node(id='Computer Science', type='Field', properties={}), type='COMPONENT', properties={}), Relationship(source=Node(id='Tcp/Ip', type='Protocol', properties={}), target=Node(id='Networking', type='Component', properties={}), type='PROTOCOL', properties={}), Relationship(source=Node(id='Internet Protocols', type='Part', properties={}), target=Node(id='Networking', type='Component', properties={}), type='PART', properties={}), Relationship(source=Node(id='Distributed Systems', type='Systems', properties={}), target=Node(id='Computer Science', type='Field', properties={}), type='SYSTEMS', properties={}), Relationship(source=Node(id='Cybersecurity', type='Field', properties={}), target=Node(id='Computer Science', type='Field', properties={}), type='FIELD', properties={}), Relationship(source=Node(id='Cryptography', type='Part', properties={}), target=Node(id='Cybersecurity', type='Field', properties={}), type='PART', properties={}), Relationship(source=Node(id='Network Security', type='Part', properties={}), target=Node(id='Cybersecurity', type='Field', properties={}), type='PART', properties={}), Relationship(source=Node(id='Information Security', type='Part', properties={}), target=Node(id='Cybersecurity', type='Field', properties={}), type='PART', properties={}), Relationship(source=Node(id='Encryption', type='Part', properties={}), target=Node(id='Cryptography', type='Part', properties={}), type='PART', properties={}), Relationship(source=Node(id='Authentication', type='Part', properties={}), target=Node(id='Security', type='Part', properties={}), type='PART', properties={}), Relationship(source=Node(id='Authorization', type='Part', properties={}), target=Node(id='Security', type='Part', properties={}), type='PART', properties={}), Relationship(source=Node(id='Penetration Testing', type='Part', properties={}), target=Node(id='Security', type='Part', properties={}), type='PART', properties={}), Relationship(source=Node(id='Data Science', type='Field', properties={}), target=Node(id='Computer Science', type='Field', properties={}), type='FIELD', properties={}), Relationship(source=Node(id='Data Analysis', type='Part', properties={}), target=Node(id='Data Science', type='Field', properties={}), type='PART', properties={}), Relationship(source=Node(id='Data Mining', type='Part', properties={}), target=Node(id='Data Science', type='Field', properties={}), type='PART', properties={}), Relationship(source=Node(id='Big Data', type='Related', properties={}), target=Node(id='Data Science', type='Field', properties={}), type='RELATED', properties={}), Relationship(source=Node(id='Data Visualization', type='Part', properties={}), target=Node(id='Data Analysis', type='Part', properties={}), type='PART', properties={}), Relationship(source=Node(id='Statistical Analysis', type='Part', properties={}), target=Node(id='Data Science', type='Field', properties={}), type='PART', properties={}), Relationship(source=Node(id='Predictive Analytics', type='Part', properties={}), target=Node(id='Data Science', type='Field', properties={}), type='PART', properties={}), Relationship(source=Node(id='Feature Engineering', type='Part', properties={}), target=Node(id='Machine Learning', type='Subset', properties={}), type='PART', properties={}), Relationship(source=Node(id='Web Development', type='Application', properties={}), target=Node(id='Computer Science', type='Field', properties={}), type='APPLICATION', properties={}), Relationship(source=Node(id='Frontend Development', type='Part', properties={}), target=Node(id='Web Development', type='Application', properties={}), type='PART', properties={}), Relationship(source=Node(id='Backend Development', type='Part', properties={}), target=Node(id='Web Development', type='Application', properties={}), type='PART', properties={}), Relationship(source=Node(id='Html', type='Used', properties={}), target=Node(id='Frontend Development', type='Part', properties={}), type='USED', properties={}), Relationship(source=Node(id='Css', type='Used', properties={}), target=Node(id='Frontend Development', type='Part', properties={}), type='USED', properties={}), Relationship(source=Node(id='Javascript Frameworks', type='Used', properties={}), target=Node(id='Frontend Development', type='Part', properties={}), type='USED', properties={}), Relationship(source=Node(id='Node.Js', type='Used', properties={}), target=Node(id='Backend Development', type='Part', properties={}), type='USED', properties={}), Relationship(source=Node(id='Restful Apis', type='Part', properties={}), target=Node(id='Web Development', type='Application', properties={}), type='PART', properties={}), Relationship(source=Node(id='Http', type='Protocol', properties={}), target=Node(id='Web Development', type='Application', properties={}), type='PROTOCOL', properties={}), Relationship(source=Node(id='Tensorflow', type='Used', properties={}), target=Node(id='Machine Learning', type='Subset', properties={}), type='USED', properties={}), Relationship(source=Node(id='Pytorch', type='Used', properties={}), target=Node(id='Machine Learning', type='Subset', properties={}), type='USED', properties={}), Relationship(source=Node(id='Kubernetes', type='Used', properties={}), target=Node(id='Devops', type='Part', properties={}), type='USED', properties={}), Relationship(source=Node(id='Docker', type='Used', properties={}), target=Node(id='Containerization', type='Used', properties={}), type='USED', properties={}), Relationship(source=Node(id='Aws', type='Platform', properties={}), target=Node(id='Cloud Computing', type='Used', properties={}), type='PLATFORM', properties={}), Relationship(source=Node(id='Azure', type='Platform', properties={}), target=Node(id='Cloud Computing', type='Used', properties={}), type='PLATFORM', properties={}), Relationship(source=Node(id='Visual Studio Code', type='Ide', properties={}), target=Node(id='Software Development', type='Used', properties={}), type='IDE', properties={}), Relationship(source=Node(id='Eclipse', type='Ide', properties={}), target=Node(id='Java', type='Language', properties={}), type='IDE', properties={}), Relationship(source=Node(id='Linux', type='Operating system', properties={}), target=Node(id='Operating Systems', type='Component', properties={}), type='OPERATING_SYSTEM', properties={}), Relationship(source=Node(id='Design Patterns', type='Part', properties={}), target=Node(id='Software Architecture', type='Part', properties={}), type='PART', properties={}), Relationship(source=Node(id='Microservices Architecture', type='Architecture', properties={}), target=Node(id='Software Architecture', type='Part', properties={}), type='ARCHITECTURE', properties={}), Relationship(source=Node(id='Mvc Pattern', type='Pattern', properties={}), target=Node(id='Design Patterns', type='Part', properties={}), type='PATTERN', properties={}), Relationship(source=Node(id='Clean Architecture', type='Principle', properties={}), target=Node(id='Software Architecture', type='Part', properties={}), type='PRINCIPLE', properties={}), Relationship(source=Node(id='Solid Principles', type='Principles', properties={}), target=Node(id='Software Design', type='Part', properties={}), type='PRINCIPLES', properties={}), Relationship(source=Node(id='Api Design', type='Part', properties={}), target=Node(id='Software Architecture', type='Part', properties={}), type='PART', properties={}), Relationship(source=Node(id='System Design', type='Part', properties={}), target=Node(id='Software Architecture', type='Part', properties={}), type='PART', properties={}), Relationship(source=Node(id='Cloud Architecture', type='Part', properties={}), target=Node(id='Software Architecture', type='Part', properties={}), type='PART', properties={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "with open(\"/kaggle/input/dl-project-dataset-interview/Knowledge INPUT.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "documents = [Document(page_content=text)]\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T17:09:09.625610Z",
     "iopub.status.busy": "2024-11-21T17:09:09.625190Z",
     "iopub.status.idle": "2024-11-21T17:09:12.866015Z",
     "shell.execute_reply": "2024-11-21T17:09:12.864831Z",
     "shell.execute_reply.started": "2024-11-21T17:09:09.625571Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph data has been stored in Neo4j.\n"
     ]
    }
   ],
   "source": [
    "graph.add_graph_documents(graph_documents)\n",
    "print(\"Graph data has been stored in Neo4j.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:33:25.339957Z",
     "iopub.status.busy": "2024-11-22T08:33:25.339496Z",
     "iopub.status.idle": "2024-11-22T08:33:25.375909Z",
     "shell.execute_reply": "2024-11-22T08:33:25.375020Z",
     "shell.execute_reply.started": "2024-11-22T08:33:25.339929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from typing import Dict, List\n",
    "\n",
    "# Instantiate the ChatGroq model\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "def create_system_prompt() -> str:\n",
    "    return \"\"\"You are a skill extraction specialist. Extract ONLY specific named skills, tools, technologies, and knowledge areas. \n",
    "    - Extract single-word or short-phrase skills ONLY\n",
    "    - DO NOT include full sentences or descriptions\n",
    "    - DO NOT include experience levels or qualifications\n",
    "    - Each skill should be a clear, standalone term\"\"\"\n",
    "\n",
    "def create_skill_extraction_prompt(text: str) -> str:\n",
    "    return f\"\"\"Extract specific skills from the text below into these categories:\n",
    "\n",
    "        Technical Skills: Specific tools, programming languages, software, platforms\n",
    "        Example: Python, SQL, Tableau, Excel\n",
    "\n",
    "        Domain Knowledge: Specific fields, subjects, methodologies\n",
    "        Example: Machine Learning, Statistics, Data Mining\n",
    "\n",
    "\n",
    "        Text: {text}\n",
    "\n",
    "        Return ONLY in this JSON format:\n",
    "        {{\n",
    "            \"technical_skills\": [\"skill1\", \"skill2\"],\n",
    "            \"domain_knowledge\": [\"domain1\", \"domain2\"],\n",
    "        }}\"\"\"\n",
    "\n",
    "def extract_skills(text: str) -> Dict[str, List[str]]:\n",
    "    messages = [\n",
    "        (\"system\", create_system_prompt()),\n",
    "        (\"human\", create_skill_extraction_prompt(text))\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    json_parser = JsonOutputParser()\n",
    "    \n",
    "    try:\n",
    "        parsed_skills = json_parser.parse(response.content)\n",
    "        return parsed_skills\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing response: {e}\")\n",
    "        return {\n",
    "            \"technical_skills\": [],\n",
    "            \"domain_knowledge\": [],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Description Skills Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:33:30.539537Z",
     "iopub.status.busy": "2024-11-22T08:33:30.539162Z",
     "iopub.status.idle": "2024-11-22T08:33:31.162704Z",
     "shell.execute_reply": "2024-11-22T08:33:31.161517Z",
     "shell.execute_reply.started": "2024-11-22T08:33:30.539509Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'technical_skills': ['SQL', 'Excel', 'XML', 'JavaScript', 'ETL', 'SPSS', 'SAS'], 'domain_knowledge': ['Data Mining', 'Data Analytics', 'Data Visualization', 'Statistics', 'Mathematics', 'Computer Science', 'Economics']}\n"
     ]
    }
   ],
   "source": [
    "# Job Description\n",
    "text = \"\"\"Sample data analyst job description\n",
    "At [Company X], we’re proud to stand at the forefront of the Big Data revolution. Using the latest analytics tools and processes, we’re able to maximize our offerings and deliver unparalleled service and support. To help carry us even further, we’re searching for an experienced data analyst to join our team. The ideal candidate will be highly skilled in all aspects of data analytics, including mining, generation, and visualization. Additionally, this person should be committed to transforming data into readable, goal-oriented reports that drive innovation and growth.\n",
    "\n",
    "Objectives of this role\n",
    "Develop, implement, and maintain leading-edge analytics systems, taking complicated problems and building simple frameworks\n",
    "Identify trends and opportunities for growth through analysis of complex datasets\n",
    "Evaluate organizational methods and provide source-to-target mappings and information-model specification documents for datasets\n",
    "Create best-practice reports based on data mining, analysis, and visualization\n",
    "Evaluate internal systems for efficiency, problems, and inaccuracies, and develop and maintain protocols for handling, processing, and cleaning data\n",
    "Work directly with managers and users to gather requirements, provide status updates, and build relationships\n",
    "Responsibilities\n",
    "Work closely with project managers to understand and maintain focus on their analytics needs, including critical metrics and KPIs, and deliver actionable insights to relevant decision-makers\n",
    "Proactively analyze data to answer key questions for stakeholders or yourself, with an eye on what drives business performance, and investigate and communicate which areas need improvement in efficiency and productivity\n",
    "Create and maintain rich interactive visualizations through data interpretation and analysis, with reporting components from multiple data sources\n",
    "Define and implement data acquisition and integration logic, selecting an appropriate combination of methods and tools within the defined technology stack to ensure optimal scalability and performance of the solution\n",
    "Develop and maintain databases by acquiring data from primary and secondary sources, and build scripts that will make our data evaluation process more flexible or scalable across datasets\n",
    "Required skills and qualifications\n",
    "Three or more years of experience mining data as a data analyst\n",
    "Proven analytics skills, including mining, evaluation, and visualization\n",
    "Technical writing experience in relevant areas, including queries, reports, and presentations\n",
    "Strong SQL or Excel skills, with aptitude for learning other analytics tools\n",
    "Preferred skills and qualifications\n",
    "Bachelor’s degree (or equivalent) in mathematics, computer science, economics, or statistics\n",
    "Experience with database and model design and segmentation techniques\n",
    "Strong programming experience with frameworks, including XML, JavaScript, and ETL\n",
    "Practical experience in statistical analysis through the use of statistical packages, including Excel, SPSS, and SAS\n",
    "Proven success in a collaborative, team-oriented environment\n",
    "\"\"\"\n",
    "\n",
    "JD_skills = extract_skills(text)\n",
    "print(JD_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:34:27.701063Z",
     "iopub.status.busy": "2024-11-22T08:34:27.700136Z",
     "iopub.status.idle": "2024-11-22T08:34:27.706748Z",
     "shell.execute_reply": "2024-11-22T08:34:27.705607Z",
     "shell.execute_reply.started": "2024-11-22T08:34:27.701029Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_relationship_prompt(new_skills: Dict[str, List[str]], existing_knowledge: Dict[str, List[str]]) -> str:\n",
    "    return f\"\"\"Given:\n",
    "\n",
    "EXISTING KNOWLEDGE GRAPH:\n",
    "Technical Skills: {', '.join(existing_knowledge)}\n",
    "\n",
    "\n",
    "NEW SKILLS TO INTEGRATE:\n",
    "Technical Skills: {', '.join(new_skills['technical_skills'])}\n",
    "Domain Knowledge: {', '.join(new_skills['domain_knowledge'])}\n",
    "\n",
    "Generate ONLY accurate and well-established relationships between skills following these rules:\n",
    "1. Only include relationships that are widely accepted in academia/industry\n",
    "2. Focus on direct, clear hierarchical relationships\n",
    "3. For tools, only state their primary purpose\n",
    "4. Avoid broad or questionable generalizations\n",
    "5. Each skill should only be related to its most direct parent/application\n",
    "\n",
    "Return relationships in numbered list format.\n",
    "Only include relationships you are completely confident about.Do not include any other text, explanations, or notes.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T03:51:49.118348Z",
     "iopub.status.busy": "2024-11-22T03:51:49.117946Z",
     "iopub.status.idle": "2024-11-22T03:51:54.332905Z",
     "shell.execute_reply": "2024-11-22T03:51:54.331932Z",
     "shell.execute_reply.started": "2024-11-22T03:51:49.118320Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Spss', type='Software', properties={}), Node(id='Sas', type='Software', properties={}), Node(id='Excel', type='Software', properties={}), Node(id='Xml', type='Language', properties={}), Node(id='Sql', type='Language', properties={}), Node(id='Etl', type='Process', properties={}), Node(id='Statistics', type='Field', properties={}), Node(id='Data Visualization', type='Field', properties={}), Node(id='Database Systems', type='Field', properties={})]\n",
      "Relationships:[Relationship(source=Node(id='Spss', type='Software', properties={}), target=Node(id='Statistics', type='Field', properties={}), type='USED_FOR', properties={}), Relationship(source=Node(id='Sas', type='Software', properties={}), target=Node(id='Statistics', type='Field', properties={}), type='USED_FOR', properties={}), Relationship(source=Node(id='Excel', type='Software', properties={}), target=Node(id='Data Visualization', type='Field', properties={}), type='USED_FOR', properties={}), Relationship(source=Node(id='Xml', type='Language', properties={}), target=Node(id='Database Systems', type='Field', properties={}), type='USED_FOR', properties={}), Relationship(source=Node(id='Sql', type='Language', properties={}), target=Node(id='Database Systems', type='Field', properties={}), type='USED_FOR', properties={}), Relationship(source=Node(id='Etl', type='Process', properties={}), target=Node(id='Database Systems', type='Field', properties={}), type='USED_FOR', properties={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from typing import Dict, List\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0.9,\n",
    ")\n",
    "\n",
    "existing_knowledge = node_names\n",
    "\n",
    "new_skills = JD_skills\n",
    "relationships = llm.invoke([\n",
    "    (\"system\", \"You are a knowledge graph relationship specialist. Create clear, ONLY really close relationships between technical concepts.\"),\n",
    "    (\"human\", create_relationship_prompt(new_skills, existing_knowledge))\n",
    "])\n",
    "\n",
    "meaning=relationships.content\n",
    "\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-70b-versatile\", temperature=0)\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "text = meaning\n",
    "documents = [Document(page_content=text)]\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")\n",
    "\n",
    "graph = Neo4jGraph(refresh_schema=False)\n",
    "graph.add_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume Skills Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:34:31.808524Z",
     "iopub.status.busy": "2024-11-22T08:34:31.808132Z",
     "iopub.status.idle": "2024-11-22T08:34:44.796023Z",
     "shell.execute_reply": "2024-11-22T08:34:44.794839Z",
     "shell.execute_reply.started": "2024-11-22T08:34:31.808493Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.24.14-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from python-docx) (5.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /opt/conda/lib/python3.10/site-packages (from python-docx) (4.12.2)\n",
      "Downloading PyMuPDF-1.24.14-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-docx, PyMuPDF\n",
      "Successfully installed PyMuPDF-1.24.14 python-docx-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF python-docx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resume parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:34:45.077634Z",
     "iopub.status.busy": "2024-11-22T08:34:45.077207Z",
     "iopub.status.idle": "2024-11-22T08:34:45.274123Z",
     "shell.execute_reply": "2024-11-22T08:34:45.273134Z",
     "shell.execute_reply.started": "2024-11-22T08:34:45.077599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import fitz\n",
    "import docx\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "class ResumeParser:\n",
    "    def __init__(self, file_path: Union[str, Path]):\n",
    "        self.file_path = Path(file_path)\n",
    "        self.text = \"\"\n",
    "\n",
    "    def extract_text(self) -> str:\n",
    "        \"\"\"Extract text based on file extension\"\"\"\n",
    "        suffix = self.file_path.suffix.lower()\n",
    "        \n",
    "        try:\n",
    "            if suffix == '.pdf':\n",
    "                return self._extract_from_pdf()\n",
    "            elif suffix == '.docx':\n",
    "                return self._extract_from_docx()\n",
    "            elif suffix == '.txt':\n",
    "                return self._extract_from_txt()\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported file format: {suffix}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from {self.file_path}: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    def _extract_from_pdf(self) -> str:\n",
    "        \"\"\"Extract text from PDF using PyMuPDF\"\"\"\n",
    "        text = []\n",
    "        with fitz.open(self.file_path) as doc:\n",
    "            for page in doc:\n",
    "                text.append(page.get_text())\n",
    "        return \"\\n\".join(text)\n",
    "\n",
    "    def _extract_from_docx(self) -> str:\n",
    "        \"\"\"Extract text from DOCX\"\"\"\n",
    "        doc = docx.Document(self.file_path)\n",
    "        return \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "\n",
    "    def _extract_from_txt(self) -> str:\n",
    "        \"\"\"Extract text from TXT\"\"\"\n",
    "        return self.file_path.read_text(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:35:13.559373Z",
     "iopub.status.busy": "2024-11-22T08:35:13.559019Z",
     "iopub.status.idle": "2024-11-22T08:35:13.616314Z",
     "shell.execute_reply": "2024-11-22T08:35:13.614937Z",
     "shell.execute_reply.started": "2024-11-22T08:35:13.559347Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revanth Srinivasa Reddy\n",
      "Hyderabad, India 500090\n",
      " +91 9492891337\n",
      "# revanthbommareddy@gmail.com\n",
      "ï LinkedIn\n",
      "§ GitHub\n",
      "Education\n",
      "Vellore Institute of Technology\n",
      "Sep. 2022 – Present\n",
      "Bachelor of Technology in Computer Science with specialization in AI & ML, CGPA: 9.22/10\n",
      "Chennai, Tamil Nadu\n",
      "Sri Chaitanya Junior College\n",
      "April. 2020 – June. 2022\n",
      "State Board (12th grade), Percentage: 92.9%\n",
      "Hyderabad, Telangana\n",
      "Vikas The Concept School\n",
      "Mar. 2019 – Mar. 2020\n",
      "CBSE (10th grade) , Percentage: 94.6%\n",
      "Hyderabad, Telangana\n",
      "Relevant Coursework\n",
      "• Data Structures and\n",
      "Algorithms\n",
      "• Generative AI\n",
      "• Natural Language\n",
      "Processing\n",
      "• Machine Learning\n",
      "• Computer Vision\n",
      "Experience\n",
      "Samsung R&D Institute, Bengaluru\n",
      "July 2024 – Present\n",
      "Samsung PRISM Intern\n",
      "Remote\n",
      "• Researching integrating Large Language Models (LLMs) into recommendation systems to demonstrate their superiority\n",
      "over existing methods by aiming for a performance improvement of at least 20%.\n",
      "• Investigating methods to improve item titles and personalization using LLMs.\n",
      "• Exploring novel evaluation metrics for LLM-enhanced recommender systems.\n",
      "• Analysing the impact and best practices of using LLMs in commercial recommendation applications\n",
      "DatafactZ\n",
      "June 2024 – Present\n",
      "Generative AI Intern\n",
      "Hyderabad, Telangana\n",
      "• Acquired in-depth knowledge of Retrieval-Augmented Generation (RAG) and LangChain, enhancing expertise in\n",
      "Generative AI techniques.\n",
      "• Currently working on a project to enable interactive chat with large product manuals using Microsoft’s GraphRAG.\n",
      "• Aiming to demonstrate that Microsoft GraphRAG improves performance by at least 25% compared to traditional RAG,\n",
      "providing more accurate and contextually relevant responses.\n",
      "Projects\n",
      "Federated Learning Model with Adaptive Clustering for Client Selection | Python, PyTorch\n",
      "Febraury 2024\n",
      "• Developed a novel federated learning model that leverages an adaptive clustering scheme to dynamically adjust the\n",
      "number of client clusters, optimizing communication costs while maintaining model performance.\n",
      "• Incorporated techniques such as Neural networks, clustering algorithms, and model aggregation.\n",
      "• Achieved an average accuracy of 99.5% when tested on the CIC-IDS-2018 dataset with 15 classes, demonstrating the\n",
      "model’s high performance and robustness in handling diverse and distributed data.\n",
      "ResChat: AI-Powered Research Paper Assistant | Python, LightRAG, Langchain, Streamlit\n",
      "November 2024\n",
      "• Developed a research paper assistant using LightRAG for efficient document retrieval and question answering,\n",
      "implementing context-aware knowledge graphs for improved information extraction.\n",
      "• Implemented a RAG system that combines semantic search with knowledge graph-based retrieval, enabling precise\n",
      "question-answering about research paper content with source-backed responses.\n",
      "• Integrated query enhancement using Groq’s LLM and implemented paper processing pipeline with asynchronous PDF\n",
      "extraction and dynamic knowledge graph generation for each paper.\n",
      "• Used PyMuPDF for PDF content extraction and integrated interactive knowledge graph visualization using PyVis and\n",
      "NetworkX to explore paper relationships and concept connections.\n",
      "Similar Document Template Matching Algorithm | Python, OpenCV\n",
      "October 2023\n",
      "• Developed a methodology for verifying medical documents using template extraction, comparison, and fraud detection\n",
      "techniques.\n",
      "• Key Features: Template extraction with ROI methods, Advanced feature matching, SSIM computation and OCR\n",
      "• Published the research and methodology on arXiv\n",
      "\n",
      "Publications\n",
      "• “Early Detection of Cardiovascular Disorders Using Enhanced ANN Model,” presented at the ADICS 2024 IEEE\n",
      "Conference, Chennai, Tamil Nadu, April. 2024 (DOI: 10.1109/ADICS58448.2024.10533530)\n",
      "• “Similar Document Template Matching Algorithm”, November. 2023 (DOI: 10.48550/arXiv.2311.12663)\n",
      "Technical Skills\n",
      "Languages: Python, Java, C, C++, HTML/CSS, JavaScript, TypeScript, SQL, R\n",
      "Libraries: Pandas, Numpy, Matplotlib, Seaborn, scikit-learn, Tensorflow, Keras, PyTorch, OpenCV, Streamlit\n",
      "Frameworks: Langchain, ReactJS, NextJS FastAPI, Flask\n",
      "Cloud Platforms: Familiarity with AWS and Microsoft Azure\n",
      "Others: Knowledge of Linux environment\n",
      "Certifications\n",
      "Microsoft Certified: Azure AI Fundamentals (AI-900)\n",
      "June. 2024\n",
      "• Demonstrates foundational knowledge of machine learning (ML) and artificial intelligence (AI) concepts and related\n",
      "Microsoft Azure services.\n",
      "Extracurricular Activities\n",
      "• Secured 113th place out of 74,000+ participants in the Amazon ML Challenge 2024, working in a 4-member team to\n",
      "develop and optimize machine learning models for real-world prediction tasks.\n",
      "• Achieved 4th place in a CodeChef domain-specific hackathon on Generative AI at VIT Chennai, as a key member of a\n",
      "four-person team.\n",
      "Volunteering\n",
      "National Service Scheme (NSS) Volunteer\n",
      "Nov. 2023 - July 2024\n",
      "• Participated in various community service activities, including blood donation camps, health awareness programs, and\n",
      "environmental conservation efforts.\n",
      "• Collaborated with local NGOs and community leaders to address social issues and improve living conditions in a nearby\n",
      "village.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_resume_text(file_path: str) -> str:\n",
    "    parser = ResumeParser(file_path)\n",
    "    return parser.extract_text()\n",
    "\n",
    "    \n",
    "resume_file = \"/kaggle/input/resume/resume_v2.3.pdf\"\n",
    "text = extract_resume_text(resume_file)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:35:20.996331Z",
     "iopub.status.busy": "2024-11-22T08:35:20.995396Z",
     "iopub.status.idle": "2024-11-22T08:35:22.378611Z",
     "shell.execute_reply": "2024-11-22T08:35:22.377313Z",
     "shell.execute_reply.started": "2024-11-22T08:35:20.996300Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'technical_skills': ['Python', 'Java', 'C', 'C++', 'HTML/CSS', 'JavaScript', 'TypeScript', 'SQL', 'R', 'Pandas', 'Numpy', 'Matplotlib', 'Seaborn', 'scikit-learn', 'Tensorflow', 'Keras', 'PyTorch', 'OpenCV', 'Streamlit', 'Langchain', 'ReactJS', 'NextJS', 'FastAPI', 'Flask', 'AWS', 'Microsoft Azure', 'Linux'], 'domain_knowledge': ['Machine Learning', 'Generative AI', 'Natural Language Processing', 'Computer Vision', 'Data Structures and Algorithms', 'Statistics', 'Data Mining']}\n"
     ]
    }
   ],
   "source": [
    "resume_skills = extract_skills(text)\n",
    "print(resume_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Text creation for Knowledge Graph generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:38:52.525674Z",
     "iopub.status.busy": "2024-11-22T08:38:52.525185Z",
     "iopub.status.idle": "2024-11-22T08:38:53.216710Z",
     "shell.execute_reply": "2024-11-22T08:38:53.215605Z",
     "shell.execute_reply.started": "2024-11-22T08:38:52.525553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n': {'id': 'Mathematics'}}\n",
      "{'n': {'id': 'Linear Algebra'}}\n",
      "{'n': {'id': 'Calculus'}}\n",
      "{'n': {'id': 'Probability'}}\n",
      "{'n': {'id': 'Statistics'}}\n",
      "{'n': {'id': 'Discrete Mathematics'}}\n",
      "{'n': {'id': 'Graph Theory'}}\n",
      "{'n': {'id': 'Number Theory'}}\n",
      "{'n': {'id': 'Combinatorics'}}\n",
      "{'n': {'id': 'Programming Languages'}}\n",
      "{'n': {'id': 'Computer Science'}}\n",
      "{'n': {'id': 'Object-Oriented Programming'}}\n",
      "{'n': {'id': 'Functional Programming'}}\n",
      "{'n': {'id': 'Procedural Programming'}}\n",
      "{'n': {'id': 'Java'}}\n",
      "{'n': {'id': 'Python'}}\n",
      "{'n': {'id': 'C++'}}\n",
      "{'n': {'id': 'Javascript'}}\n",
      "{'n': {'id': 'Assembly Language'}}\n",
      "{'n': {'id': 'Database Systems'}}\n",
      "{'n': {'id': 'Sql'}}\n",
      "{'n': {'id': 'Nosql'}}\n",
      "{'n': {'id': 'Mongodb'}}\n",
      "{'n': {'id': 'Postgresql'}}\n",
      "{'n': {'id': 'Database Design'}}\n",
      "{'n': {'id': 'Data Modeling'}}\n",
      "{'n': {'id': 'Normalization'}}\n",
      "{'n': {'id': 'Query Optimization'}}\n",
      "{'n': {'id': 'Artificial Intelligence'}}\n",
      "{'n': {'id': 'Machine Learning'}}\n",
      "{'n': {'id': 'Deep Learning'}}\n",
      "{'n': {'id': 'Neural Networks'}}\n",
      "{'n': {'id': 'Natural Language Processing'}}\n",
      "{'n': {'id': 'Computer Vision'}}\n",
      "{'n': {'id': 'Reinforcement Learning'}}\n",
      "{'n': {'id': 'Supervised Learning'}}\n",
      "{'n': {'id': 'Unsupervised Learning'}}\n",
      "{'n': {'id': 'Software Engineering'}}\n",
      "{'n': {'id': 'Software Development Life Cycle'}}\n",
      "{'n': {'id': 'Version Control'}}\n",
      "{'n': {'id': 'Git'}}\n",
      "{'n': {'id': 'Testing'}}\n",
      "{'n': {'id': 'Unit Testing'}}\n",
      "{'n': {'id': 'Integration Testing'}}\n",
      "{'n': {'id': 'Agile Development'}}\n",
      "{'n': {'id': 'Devops'}}\n",
      "{'n': {'id': 'Operating Systems'}}\n",
      "{'n': {'id': 'Computer Architecture'}}\n",
      "{'n': {'id': 'Memory Management'}}\n",
      "{'n': {'id': 'Process Management'}}\n",
      "{'n': {'id': 'File Systems'}}\n",
      "{'n': {'id': 'Networking'}}\n",
      "{'n': {'id': 'Tcp/Ip'}}\n",
      "{'n': {'id': 'Internet Protocols'}}\n",
      "{'n': {'id': 'Distributed Systems'}}\n",
      "{'n': {'id': 'Cybersecurity'}}\n",
      "{'n': {'id': 'Cryptography'}}\n",
      "{'n': {'id': 'Network Security'}}\n",
      "{'n': {'id': 'Information Security'}}\n",
      "{'n': {'id': 'Encryption'}}\n",
      "{'n': {'id': 'Authentication'}}\n",
      "{'n': {'id': 'Authorization'}}\n",
      "{'n': {'id': 'Penetration Testing'}}\n",
      "{'n': {'id': 'Data Science'}}\n",
      "{'n': {'id': 'Data Analysis'}}\n",
      "{'n': {'id': 'Data Mining'}}\n",
      "{'n': {'id': 'Big Data'}}\n",
      "{'n': {'id': 'Data Visualization'}}\n",
      "{'n': {'id': 'Statistical Analysis'}}\n",
      "{'n': {'id': 'Predictive Analytics'}}\n",
      "{'n': {'id': 'Feature Engineering'}}\n",
      "{'n': {'id': 'Web Development'}}\n",
      "{'n': {'id': 'Frontend Development'}}\n",
      "{'n': {'id': 'Backend Development'}}\n",
      "{'n': {'id': 'Html'}}\n",
      "{'n': {'id': 'Css'}}\n",
      "{'n': {'id': 'Javascript Frameworks'}}\n",
      "{'n': {'id': 'Node.Js'}}\n",
      "{'n': {'id': 'Restful Apis'}}\n",
      "{'n': {'id': 'Http'}}\n",
      "{'n': {'id': 'Tensorflow'}}\n",
      "{'n': {'id': 'Pytorch'}}\n",
      "{'n': {'id': 'Kubernetes'}}\n",
      "{'n': {'id': 'Docker'}}\n",
      "{'n': {'id': 'Aws'}}\n",
      "{'n': {'id': 'Azure'}}\n",
      "{'n': {'id': 'Visual Studio Code'}}\n",
      "{'n': {'id': 'Eclipse'}}\n",
      "{'n': {'id': 'Linux'}}\n",
      "{'n': {'id': 'Design Patterns'}}\n",
      "{'n': {'id': 'Microservices Architecture'}}\n",
      "{'n': {'id': 'Mvc Pattern'}}\n",
      "{'n': {'id': 'Clean Architecture'}}\n",
      "{'n': {'id': 'Solid Principles'}}\n",
      "{'n': {'id': 'Api Design'}}\n",
      "{'n': {'id': 'System Design'}}\n",
      "{'n': {'id': 'Cloud Architecture'}}\n",
      "{'n': {'id': 'Security'}}\n",
      "{'n': {'id': 'Containerization'}}\n",
      "{'n': {'id': 'Cloud Computing'}}\n",
      "{'n': {'id': 'Software Development'}}\n",
      "{'n': {'id': 'Software Architecture'}}\n",
      "{'n': {'id': 'Software Design'}}\n",
      "{'n': {'id': 'Pytorch'}}\n",
      "{'n': {'id': 'Scikit-Learn'}}\n",
      "{'n': {'id': 'Keras'}}\n",
      "{'n': {'id': 'Pandas'}}\n",
      "{'n': {'id': 'Numpy'}}\n",
      "{'n': {'id': 'Fastapi'}}\n",
      "{'n': {'id': 'Reactjs'}}\n",
      "{'n': {'id': 'Langchain'}}\n",
      "{'n': {'id': 'Ocr'}}\n",
      "{'n': {'id': 'Ann Model'}}\n",
      "{'n': {'id': 'Generative Ai'}}\n",
      "{'n': {'id': 'Model Aggregation'}}\n",
      "{'n': {'id': 'Template Extraction'}}\n",
      "{'n': {'id': 'C'}}\n",
      "{'n': {'id': 'Java'}}\n",
      "{'n': {'id': 'C++'}}\n",
      "{'n': {'id': 'Oracle Sql'}}\n",
      "{'n': {'id': 'Machine Learning'}}\n",
      "{'n': {'id': 'Artificial Intelligence'}}\n",
      "{'n': {'id': 'Deep Learning'}}\n",
      "{'n': {'id': 'Neural Networks'}}\n",
      "{'n': {'id': 'Natural Language Processing'}}\n",
      "{'n': {'id': 'Computer Vision'}}\n",
      "{'n': {'id': 'Reinforcement Learning'}}\n",
      "{'n': {'id': 'Supervised Learning'}}\n",
      "{'n': {'id': 'Unsupervised Learning'}}\n",
      "{'n': {'id': 'Data Science'}}\n",
      "{'n': {'id': 'Data Analysis'}}\n",
      "{'n': {'id': 'Data Mining'}}\n",
      "{'n': {'id': 'Big Data'}}\n",
      "{'n': {'id': 'Data Visualization'}}\n",
      "{'n': {'id': 'Statistical Analysis'}}\n",
      "{'n': {'id': 'Predictive Analytics'}}\n",
      "{'n': {'id': 'Feature Engineering'}}\n",
      "{'n': {'id': 'Frontend Development'}}\n",
      "{'n': {'id': 'Backend Development'}}\n",
      "{'n': {'id': 'Html'}}\n",
      "{'n': {'id': 'Css'}}\n",
      "{'n': {'id': 'Javascript Frameworks'}}\n",
      "{'n': {'id': 'Node.Js'}}\n",
      "{'n': {'id': 'Restful Apis'}}\n",
      "{'n': {'id': 'Http'}}\n",
      "{'n': {'id': 'Tensorflow'}}\n",
      "{'n': {'id': 'Pytorch'}}\n",
      "{'n': {'id': 'Scikit-Learn'}}\n",
      "{'n': {'id': 'Keras'}}\n",
      "{'n': {'id': 'Pandas'}}\n",
      "{'n': {'id': 'Numpy'}}\n",
      "{'n': {'id': 'Fastapi'}}\n",
      "{'n': {'id': 'Reactjs'}}\n",
      "{'n': {'id': 'Langchain'}}\n",
      "{'n': {'id': 'Ocr'}}\n",
      "{'n': {'id': 'Ann Model'}}\n",
      "{'n': {'id': 'Generative Ai'}}\n",
      "{'n': {'id': 'Model Aggregation'}}\n",
      "{'n': {'id': 'Template Extraction'}}\n",
      "{'n': {'id': 'C'}}\n",
      "{'n': {'id': 'Visual Studio Code'}}\n",
      "{'n': {'id': 'Eclipse'}}\n",
      "{'n': {'id': 'Linux'}}\n",
      "{'n': {'id': 'Design Patterns'}}\n",
      "{'n': {'id': 'Microservices Architecture'}}\n",
      "{'n': {'id': 'Mvc Pattern'}}\n",
      "{'n': {'id': 'Clean Architecture'}}\n",
      "{'n': {'id': 'Solid Principles'}}\n",
      "{'n': {'id': 'Api Design'}}\n",
      "{'n': {'id': 'System Design'}}\n",
      "{'n': {'id': 'Cloud Architecture'}}\n",
      "{'n': {'id': 'Containerization'}}\n",
      "{'n': {'id': 'Cloud Computing'}}\n",
      "{'n': {'id': 'Distributed Systems'}}\n",
      "{'n': {'id': 'Domain Knowledge'}}\n",
      "{'n': {'id': 'Web Development'}}\n",
      "{'n': {'id': 'Software Development'}}\n",
      "{'n': {'id': 'Software Design'}}\n",
      "{'n': {'id': 'Software Architecture'}}\n",
      "{'n': {'id': 'Operating Systems'}}\n",
      "{'n': {'id': 'Programming Languages'}}\n",
      "{'n': {'id': 'Numpy'}}\n",
      "{'n': {'id': 'Model Aggregation'}}\n",
      "{'n': {'id': 'Template Extraction'}}\n",
      "{'n': {'id': 'Clustering Algorithms'}}\n",
      "{'n': {'id': 'Feature Matching'}}\n",
      "{'n': {'id': 'Fraud Detection'}}\n",
      "{'n': {'id': 'Cardiovascular Disorders'}}\n",
      "{'n': {'id': 'Spss'}}\n",
      "{'n': {'id': 'Sas'}}\n",
      "{'n': {'id': 'Excel'}}\n",
      "{'n': {'id': 'Xml'}}\n",
      "{'n': {'id': 'Etl'}}\n",
      "{'n': {'id': 'Statistics'}}\n",
      "{'n': {'id': 'Data Visualization'}}\n",
      "{'n': {'id': 'Database Systems'}}\n",
      "Node Names:\n",
      "Mathematics\n",
      "Linear Algebra\n",
      "Calculus\n",
      "Probability\n",
      "Statistics\n",
      "Discrete Mathematics\n",
      "Graph Theory\n",
      "Number Theory\n",
      "Combinatorics\n",
      "Programming Languages\n",
      "Computer Science\n",
      "Object-Oriented Programming\n",
      "Functional Programming\n",
      "Procedural Programming\n",
      "Java\n",
      "Python\n",
      "C++\n",
      "Javascript\n",
      "Assembly Language\n",
      "Database Systems\n",
      "Sql\n",
      "Nosql\n",
      "Mongodb\n",
      "Postgresql\n",
      "Database Design\n",
      "Data Modeling\n",
      "Normalization\n",
      "Query Optimization\n",
      "Artificial Intelligence\n",
      "Machine Learning\n",
      "Deep Learning\n",
      "Neural Networks\n",
      "Natural Language Processing\n",
      "Computer Vision\n",
      "Reinforcement Learning\n",
      "Supervised Learning\n",
      "Unsupervised Learning\n",
      "Software Engineering\n",
      "Software Development Life Cycle\n",
      "Version Control\n",
      "Git\n",
      "Testing\n",
      "Unit Testing\n",
      "Integration Testing\n",
      "Agile Development\n",
      "Devops\n",
      "Operating Systems\n",
      "Computer Architecture\n",
      "Memory Management\n",
      "Process Management\n",
      "File Systems\n",
      "Networking\n",
      "Tcp/Ip\n",
      "Internet Protocols\n",
      "Distributed Systems\n",
      "Cybersecurity\n",
      "Cryptography\n",
      "Network Security\n",
      "Information Security\n",
      "Encryption\n",
      "Authentication\n",
      "Authorization\n",
      "Penetration Testing\n",
      "Data Science\n",
      "Data Analysis\n",
      "Data Mining\n",
      "Big Data\n",
      "Data Visualization\n",
      "Statistical Analysis\n",
      "Predictive Analytics\n",
      "Feature Engineering\n",
      "Web Development\n",
      "Frontend Development\n",
      "Backend Development\n",
      "Html\n",
      "Css\n",
      "Javascript Frameworks\n",
      "Node.Js\n",
      "Restful Apis\n",
      "Http\n",
      "Tensorflow\n",
      "Pytorch\n",
      "Kubernetes\n",
      "Docker\n",
      "Aws\n",
      "Azure\n",
      "Visual Studio Code\n",
      "Eclipse\n",
      "Linux\n",
      "Design Patterns\n",
      "Microservices Architecture\n",
      "Mvc Pattern\n",
      "Clean Architecture\n",
      "Solid Principles\n",
      "Api Design\n",
      "System Design\n",
      "Cloud Architecture\n",
      "Security\n",
      "Containerization\n",
      "Cloud Computing\n",
      "Software Development\n",
      "Software Architecture\n",
      "Software Design\n",
      "Pytorch\n",
      "Scikit-Learn\n",
      "Keras\n",
      "Pandas\n",
      "Numpy\n",
      "Fastapi\n",
      "Reactjs\n",
      "Langchain\n",
      "Ocr\n",
      "Ann Model\n",
      "Generative Ai\n",
      "Model Aggregation\n",
      "Template Extraction\n",
      "C\n",
      "Java\n",
      "C++\n",
      "Oracle Sql\n",
      "Machine Learning\n",
      "Artificial Intelligence\n",
      "Deep Learning\n",
      "Neural Networks\n",
      "Natural Language Processing\n",
      "Computer Vision\n",
      "Reinforcement Learning\n",
      "Supervised Learning\n",
      "Unsupervised Learning\n",
      "Data Science\n",
      "Data Analysis\n",
      "Data Mining\n",
      "Big Data\n",
      "Data Visualization\n",
      "Statistical Analysis\n",
      "Predictive Analytics\n",
      "Feature Engineering\n",
      "Frontend Development\n",
      "Backend Development\n",
      "Html\n",
      "Css\n",
      "Javascript Frameworks\n",
      "Node.Js\n",
      "Restful Apis\n",
      "Http\n",
      "Tensorflow\n",
      "Pytorch\n",
      "Scikit-Learn\n",
      "Keras\n",
      "Pandas\n",
      "Numpy\n",
      "Fastapi\n",
      "Reactjs\n",
      "Langchain\n",
      "Ocr\n",
      "Ann Model\n",
      "Generative Ai\n",
      "Model Aggregation\n",
      "Template Extraction\n",
      "C\n",
      "Visual Studio Code\n",
      "Eclipse\n",
      "Linux\n",
      "Design Patterns\n",
      "Microservices Architecture\n",
      "Mvc Pattern\n",
      "Clean Architecture\n",
      "Solid Principles\n",
      "Api Design\n",
      "System Design\n",
      "Cloud Architecture\n",
      "Containerization\n",
      "Cloud Computing\n",
      "Distributed Systems\n",
      "Domain Knowledge\n",
      "Web Development\n",
      "Software Development\n",
      "Software Design\n",
      "Software Architecture\n",
      "Operating Systems\n",
      "Programming Languages\n",
      "Numpy\n",
      "Model Aggregation\n",
      "Template Extraction\n",
      "Clustering Algorithms\n",
      "Feature Matching\n",
      "Fraud Detection\n",
      "Cardiovascular Disorders\n",
      "Spss\n",
      "Sas\n",
      "Excel\n",
      "Xml\n",
      "Etl\n",
      "Statistics\n",
      "Data Visualization\n",
      "Database Systems\n"
     ]
    }
   ],
   "source": [
    "def get_all_node_names():\n",
    "    query = \"MATCH (n) RETURN n\"\n",
    "    nodes = graph.query(query)\n",
    "    for node in nodes:\n",
    "        print(node)\n",
    "    return [node['n']['id'] for node in nodes]\n",
    "\n",
    "node_names = get_all_node_names()\n",
    "print(\"Node Names:\")\n",
    "for name in node_names:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:38:53.218711Z",
     "iopub.status.busy": "2024-11-22T08:38:53.218380Z",
     "iopub.status.idle": "2024-11-22T08:38:57.629163Z",
     "shell.execute_reply": "2024-11-22T08:38:57.628209Z",
     "shell.execute_reply.started": "2024-11-22T08:38:53.218685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from typing import Dict, List\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0.9,\n",
    ")\n",
    "\n",
    "# def create_relationship_prompt(new_skills: Dict[str, List[str]], existing_knowledge: Dict[str, List[str]]) -> str:\n",
    "#     return f\"\"\"Given:\n",
    "\n",
    "# EXISTING KNOWLEDGE GRAPH:\n",
    "# Technical Skills: {', '.join(existing_knowledge)}\n",
    "\n",
    "\n",
    "# NEW SKILLS TO INTEGRATE:\n",
    "# Technical Skills: {', '.join(new_skills['technical_skills'])}\n",
    "# Domain Knowledge: {', '.join(new_skills['domain_knowledge'])}\n",
    "\n",
    "# Generate ONLY accurate and well-established relationships between skills following these rules:\n",
    "# 1. Only include relationships that are widely accepted in academia/industry\n",
    "# 2. Focus on direct, clear hierarchical relationships\n",
    "# 3. For tools, only state their primary purpose\n",
    "# 4. Avoid broad or questionable generalizations\n",
    "# 5. Each skill should only be related to its most direct parent/application\n",
    "\n",
    "# Return relationships in numbered list format.\n",
    "# Only include relationships you are completely confident about.Do not include any other text, explanations, or notes.\"\"\"\n",
    "\n",
    "existing_knowledge = node_names\n",
    "\n",
    "new_skills = resume_skills\n",
    "relationships = llm.invoke([\n",
    "    (\"system\", \"You are a knowledge graph relationship specialist. Create clear, ONLY really close relationships between technical concepts.\"),\n",
    "    (\"human\", create_relationship_prompt(new_skills, existing_knowledge))\n",
    "])\n",
    "\n",
    "meaning=relationships.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:39:02.971319Z",
     "iopub.status.busy": "2024-11-22T08:39:02.970948Z",
     "iopub.status.idle": "2024-11-22T08:39:23.640489Z",
     "shell.execute_reply": "2024-11-22T08:39:23.639358Z",
     "shell.execute_reply.started": "2024-11-22T08:39:02.971290Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Mathematics', type='Field of study', properties={}), Node(id='Linear Algebra', type='Field of study', properties={}), Node(id='Calculus', type='Field of study', properties={}), Node(id='Probability', type='Field of study', properties={}), Node(id='Statistics', type='Field of study', properties={}), Node(id='Data Science', type='Field of study', properties={}), Node(id='Predictive Analytics', type='Field of study', properties={}), Node(id='Feature Engineering', type='Field of study', properties={}), Node(id='Data Mining', type='Field of study', properties={}), Node(id='Big Data', type='Field of study', properties={}), Node(id='Data Visualization', type='Field of study', properties={}), Node(id='Discrete Mathematics', type='Field of study', properties={}), Node(id='Graph Theory', type='Field of study', properties={}), Node(id='Combinatorics', type='Field of study', properties={}), Node(id='Number Theory', type='Field of study', properties={}), Node(id='Computer Science', type='Field of study', properties={}), Node(id='Software Engineering', type='Field of study', properties={}), Node(id='Agile Development', type='Field of study', properties={}), Node(id='Cloud Architecture', type='Field of study', properties={}), Node(id='Devops', type='Field of study', properties={}), Node(id='Data Structures And Algorithms', type='Field of study', properties={}), Node(id='Machine Learning', type='Field of study', properties={}), Node(id='Deep Learning', type='Field of study', properties={}), Node(id='Neural Networks', type='Field of study', properties={}), Node(id='Computer Vision', type='Field of study', properties={}), Node(id='Generative Ai', type='Field of study', properties={}), Node(id='Model Aggregation', type='Field of study', properties={}), Node(id='Template Extraction', type='Field of study', properties={}), Node(id='Langchain', type='Field of study', properties={}), Node(id='Natural Language Processing', type='Field of study', properties={}), Node(id='Operating Systems', type='Field of study', properties={}), Node(id='Memory Management', type='Field of study', properties={}), Node(id='Process Management', type='Field of study', properties={}), Node(id='Computer Architecture', type='Field of study', properties={}), Node(id='Opencv', type='Library', properties={}), Node(id='Programming Languages', type='Field of study', properties={}), Node(id='Object-Oriented Programming', type='Programming paradigm', properties={}), Node(id='Functional Programming', type='Programming paradigm', properties={}), Node(id='Procedural Programming', type='Programming paradigm', properties={}), Node(id='Java', type='Programming language', properties={}), Node(id='C++', type='Programming language', properties={}), Node(id='Python', type='Programming language', properties={}), Node(id='C', type='Programming language', properties={}), Node(id='Database Systems', type='Field of study', properties={}), Node(id='Sql', type='Programming language', properties={}), Node(id='Database Design', type='Field of study', properties={}), Node(id='Data Modeling', type='Field of study', properties={}), Node(id='Normalization', type='Field of study', properties={}), Node(id='Nosql', type='Database type', properties={}), Node(id='Mongodb', type='Database system', properties={}), Node(id='Postgresql', type='Database system', properties={}), Node(id='Artificial Intelligence', type='Field of study', properties={}), Node(id='Supervised Learning', type='Machine learning type', properties={}), Node(id='Unsupervised Learning', type='Machine learning type', properties={}), Node(id='Reinforcement Learning', type='Machine learning type', properties={}), Node(id='Scikit-Learn', type='Library', properties={}), Node(id='Clustering Algorithms', type='Machine learning algorithm', properties={}), Node(id='Feature Matching', type='Machine learning algorithm', properties={}), Node(id='R', type='Programming language', properties={}), Node(id='Matplotlib', type='Library', properties={}), Node(id='Seaborn', type='Library', properties={}), Node(id='Pandas', type='Library', properties={}), Node(id='Numpy', type='Library', properties={}), Node(id='Tensorflow', type='Library', properties={}), Node(id='Pytorch', type='Library', properties={}), Node(id='Keras', type='Library', properties={}), Node(id='Matrix Operations', type='Mathematical operation', properties={}), Node(id='Fastapi', type='Framework', properties={}), Node(id='Backend Development', type='Field of study', properties={}), Node(id='Restful Apis', type='Api type', properties={}), Node(id='Html/Css', type='Markup language', properties={}), Node(id='Javascript', type='Programming language', properties={}), Node(id='Http', type='Protocol', properties={}), Node(id='Frontend Development', type='Field of study', properties={}), Node(id='Reactjs', type='Library', properties={}), Node(id='Nextjs', type='Library', properties={}), Node(id='Streamlit', type='Library', properties={}), Node(id='Aws', type='Cloud provider', properties={}), Node(id='Microsoft Azure', type='Cloud provider', properties={}), Node(id='Cloud Computing', type='Field of study', properties={}), Node(id='Containerization', type='Field of study', properties={}), Node(id='Docker', type='Containerization platform', properties={}), Node(id='Kubernetes', type='Containerization platform', properties={}), Node(id='Linux', type='Operating system', properties={}), Node(id='Web Development', type='Field of study', properties={}), Node(id='Typescript', type='Programming language', properties={})]\n",
      "Relationships:[Relationship(source=Node(id='Mathematics', type='Field of study', properties={}), target=Node(id='Linear Algebra', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Linear Algebra', type='Field of study', properties={}), target=Node(id='Calculus', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Calculus', type='Field of study', properties={}), target=Node(id='Probability', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Probability', type='Field of study', properties={}), target=Node(id='Statistics', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Statistics', type='Field of study', properties={}), target=Node(id='Data Science', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Data Science', type='Field of study', properties={}), target=Node(id='Predictive Analytics', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Predictive Analytics', type='Field of study', properties={}), target=Node(id='Feature Engineering', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Predictive Analytics', type='Field of study', properties={}), target=Node(id='Data Mining', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Data Mining', type='Field of study', properties={}), target=Node(id='Big Data', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Big Data', type='Field of study', properties={}), target=Node(id='Data Visualization', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Linear Algebra', type='Field of study', properties={}), target=Node(id='Discrete Mathematics', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Discrete Mathematics', type='Field of study', properties={}), target=Node(id='Graph Theory', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Discrete Mathematics', type='Field of study', properties={}), target=Node(id='Combinatorics', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Combinatorics', type='Field of study', properties={}), target=Node(id='Number Theory', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Calculus', type='Field of study', properties={}), target=Node(id='Computer Science', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Computer Science', type='Field of study', properties={}), target=Node(id='Software Engineering', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Software Engineering', type='Field of study', properties={}), target=Node(id='Agile Development', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Software Engineering', type='Field of study', properties={}), target=Node(id='Cloud Architecture', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Cloud Architecture', type='Field of study', properties={}), target=Node(id='Devops', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Computer Science', type='Field of study', properties={}), target=Node(id='Data Structures And Algorithms', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Data Structures And Algorithms', type='Field of study', properties={}), target=Node(id='Machine Learning', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Machine Learning', type='Field of study', properties={}), target=Node(id='Deep Learning', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Deep Learning', type='Field of study', properties={}), target=Node(id='Neural Networks', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Neural Networks', type='Field of study', properties={}), target=Node(id='Computer Vision', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Computer Vision', type='Field of study', properties={}), target=Node(id='Generative Ai', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Generative Ai', type='Field of study', properties={}), target=Node(id='Model Aggregation', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Generative Ai', type='Field of study', properties={}), target=Node(id='Template Extraction', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Generative Ai', type='Field of study', properties={}), target=Node(id='Langchain', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Machine Learning', type='Field of study', properties={}), target=Node(id='Natural Language Processing', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Computer Science', type='Field of study', properties={}), target=Node(id='Operating Systems', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Operating Systems', type='Field of study', properties={}), target=Node(id='Memory Management', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Operating Systems', type='Field of study', properties={}), target=Node(id='Process Management', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Memory Management', type='Field of study', properties={}), target=Node(id='Computer Architecture', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Computer Vision', type='Field of study', properties={}), target=Node(id='Opencv', type='Library', properties={}), type='USES', properties={}), Relationship(source=Node(id='Programming Languages', type='Field of study', properties={}), target=Node(id='Object-Oriented Programming', type='Programming paradigm', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Programming Languages', type='Field of study', properties={}), target=Node(id='Functional Programming', type='Programming paradigm', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Programming Languages', type='Field of study', properties={}), target=Node(id='Procedural Programming', type='Programming paradigm', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Object-Oriented Programming', type='Programming paradigm', properties={}), target=Node(id='Java', type='Programming language', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Object-Oriented Programming', type='Programming paradigm', properties={}), target=Node(id='C++', type='Programming language', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Object-Oriented Programming', type='Programming paradigm', properties={}), target=Node(id='Python', type='Programming language', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Functional Programming', type='Programming paradigm', properties={}), target=Node(id='Python', type='Programming language', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Procedural Programming', type='Programming paradigm', properties={}), target=Node(id='C', type='Programming language', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Database Systems', type='Field of study', properties={}), target=Node(id='Sql', type='Programming language', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Sql', type='Programming language', properties={}), target=Node(id='Database Design', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Database Design', type='Field of study', properties={}), target=Node(id='Data Modeling', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Database Design', type='Field of study', properties={}), target=Node(id='Normalization', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Database Systems', type='Field of study', properties={}), target=Node(id='Nosql', type='Database type', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Nosql', type='Database type', properties={}), target=Node(id='Mongodb', type='Database system', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Nosql', type='Database type', properties={}), target=Node(id='Postgresql', type='Database system', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Artificial Intelligence', type='Field of study', properties={}), target=Node(id='Machine Learning', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Artificial Intelligence', type='Field of study', properties={}), target=Node(id='Deep Learning', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Artificial Intelligence', type='Field of study', properties={}), target=Node(id='Natural Language Processing', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Artificial Intelligence', type='Field of study', properties={}), target=Node(id='Computer Vision', type='Field of study', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Machine Learning', type='Field of study', properties={}), target=Node(id='Supervised Learning', type='Machine learning type', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Machine Learning', type='Field of study', properties={}), target=Node(id='Unsupervised Learning', type='Machine learning type', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Machine Learning', type='Field of study', properties={}), target=Node(id='Reinforcement Learning', type='Machine learning type', properties={}), type='SUBFIELD_OF', properties={}), Relationship(source=Node(id='Supervised Learning', type='Machine learning type', properties={}), target=Node(id='Scikit-Learn', type='Library', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Unsupervised Learning', type='Machine learning type', properties={}), target=Node(id='Clustering Algorithms', type='Machine learning algorithm', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Unsupervised Learning', type='Machine learning type', properties={}), target=Node(id='Feature Matching', type='Machine learning algorithm', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Reinforcement Learning', type='Machine learning type', properties={}), target=Node(id='Generative Ai', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Reinforcement Learning', type='Machine learning type', properties={}), target=Node(id='Model Aggregation', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Machine Learning', type='Field of study', properties={}), target=Node(id='R', type='Programming language', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Machine Learning', type='Field of study', properties={}), target=Node(id='Python', type='Programming language', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Python', type='Programming language', properties={}), target=Node(id='Matplotlib', type='Library', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Python', type='Programming language', properties={}), target=Node(id='Seaborn', type='Library', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Python', type='Programming language', properties={}), target=Node(id='Pandas', type='Library', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Python', type='Programming language', properties={}), target=Node(id='Numpy', type='Library', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Python', type='Programming language', properties={}), target=Node(id='Scikit-Learn', type='Library', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Python', type='Programming language', properties={}), target=Node(id='Tensorflow', type='Library', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Python', type='Programming language', properties={}), target=Node(id='Pytorch', type='Library', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Python', type='Programming language', properties={}), target=Node(id='Keras', type='Library', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Numpy', type='Library', properties={}), target=Node(id='Matrix Operations', type='Mathematical operation', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Numpy', type='Library', properties={}), target=Node(id='Linear Algebra', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Matplotlib', type='Library', properties={}), target=Node(id='Data Visualization', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Seaborn', type='Library', properties={}), target=Node(id='Data Visualization', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Pandas', type='Library', properties={}), target=Node(id='Data Analysis', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Pandas', type='Library', properties={}), target=Node(id='Data Mining', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Scikit-Learn', type='Library', properties={}), target=Node(id='Data Mining', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Scikit-Learn', type='Library', properties={}), target=Node(id='Data Analysis', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Tensorflow', type='Library', properties={}), target=Node(id='Deep Learning', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Tensorflow', type='Library', properties={}), target=Node(id='Neural Networks', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Pytorch', type='Library', properties={}), target=Node(id='Deep Learning', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Pytorch', type='Library', properties={}), target=Node(id='Neural Networks', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Keras', type='Library', properties={}), target=Node(id='Deep Learning', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Keras', type='Library', properties={}), target=Node(id='Neural Networks', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Machine Learning', type='Field of study', properties={}), target=Node(id='Fastapi', type='Framework', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Fastapi', type='Framework', properties={}), target=Node(id='Backend Development', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Fastapi', type='Framework', properties={}), target=Node(id='Restful Apis', type='Api type', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Backend Development', type='Field of study', properties={}), target=Node(id='Html/Css', type='Markup language', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Backend Development', type='Field of study', properties={}), target=Node(id='Javascript', type='Programming language', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Restful Apis', type='Api type', properties={}), target=Node(id='Http', type='Protocol', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Machine Learning', type='Field of study', properties={}), target=Node(id='Frontend Development', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Frontend Development', type='Field of study', properties={}), target=Node(id='Reactjs', type='Library', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Frontend Development', type='Field of study', properties={}), target=Node(id='Nextjs', type='Library', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Reactjs', type='Library', properties={}), target=Node(id='Javascript', type='Programming language', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Nextjs', type='Library', properties={}), target=Node(id='Javascript', type='Programming language', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Machine Learning', type='Field of study', properties={}), target=Node(id='Langchain', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Langchain', type='Field of study', properties={}), target=Node(id='Natural Language Processing', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Langchain', type='Field of study', properties={}), target=Node(id='Generative Ai', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Machine Learning', type='Field of study', properties={}), target=Node(id='Streamlit', type='Library', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Streamlit', type='Library', properties={}), target=Node(id='Data Science', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Streamlit', type='Library', properties={}), target=Node(id='Data Visualization', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Machine Learning', type='Field of study', properties={}), target=Node(id='Aws', type='Cloud provider', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Machine Learning', type='Field of study', properties={}), target=Node(id='Microsoft Azure', type='Cloud provider', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Aws', type='Cloud provider', properties={}), target=Node(id='Cloud Computing', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Microsoft Azure', type='Cloud provider', properties={}), target=Node(id='Cloud Computing', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Cloud Computing', type='Field of study', properties={}), target=Node(id='Devops', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Cloud Computing', type='Field of study', properties={}), target=Node(id='Cloud Architecture', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Cloud Architecture', type='Field of study', properties={}), target=Node(id='Containerization', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Containerization', type='Field of study', properties={}), target=Node(id='Docker', type='Containerization platform', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Containerization', type='Field of study', properties={}), target=Node(id='Kubernetes', type='Containerization platform', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Linux', type='Operating system', properties={}), target=Node(id='Operating Systems', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Html/Css', type='Markup language', properties={}), target=Node(id='Web Development', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Javascript', type='Programming language', properties={}), target=Node(id='Web Development', type='Field of study', properties={}), type='IMPLEMENTED_IN', properties={}), Relationship(source=Node(id='Typescript', type='Programming language', properties={}), target=Node(id='Javascript', type='Programming language', properties={}), type='IMPLEMENTED_IN', properties={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-70b-versatile\", temperature=0.9)\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "text = meaning\n",
    "documents = [Document(page_content=text)]\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:41:12.617121Z",
     "iopub.status.busy": "2024-11-22T08:41:12.616754Z",
     "iopub.status.idle": "2024-11-22T08:41:17.365744Z",
     "shell.execute_reply": "2024-11-22T08:41:17.364643Z",
     "shell.execute_reply.started": "2024-11-22T08:41:12.617094Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(refresh_schema=False)\n",
    "graph.add_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T18:54:26.283218Z",
     "iopub.status.busy": "2024-11-21T18:54:26.282737Z",
     "iopub.status.idle": "2024-11-21T18:54:26.294330Z",
     "shell.execute_reply": "2024-11-21T18:54:26.293251Z",
     "shell.execute_reply.started": "2024-11-21T18:54:26.283179Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'technical_skills': ['SQL',\n",
       "  'Excel',\n",
       "  'XML',\n",
       "  'JavaScript',\n",
       "  'ETL',\n",
       "  'SPSS',\n",
       "  'SAS'],\n",
       " 'domain_knowledge': ['Data Mining',\n",
       "  'Data Analytics',\n",
       "  'Data Visualization',\n",
       "  'Statistics',\n",
       "  'Machine Learning',\n",
       "  'Database Design',\n",
       "  'Statistical Analysis']}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JD_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:38:19.681264Z",
     "iopub.status.busy": "2024-11-22T08:38:19.680781Z",
     "iopub.status.idle": "2024-11-22T08:38:19.689832Z",
     "shell.execute_reply": "2024-11-22T08:38:19.688637Z",
     "shell.execute_reply.started": "2024-11-22T08:38:19.681229Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'technical_skills': ['Python',\n",
       "  'Java',\n",
       "  'C',\n",
       "  'C++',\n",
       "  'HTML/CSS',\n",
       "  'JavaScript',\n",
       "  'TypeScript',\n",
       "  'SQL',\n",
       "  'R',\n",
       "  'Pandas',\n",
       "  'Numpy',\n",
       "  'Matplotlib',\n",
       "  'Seaborn',\n",
       "  'scikit-learn',\n",
       "  'Tensorflow',\n",
       "  'Keras',\n",
       "  'PyTorch',\n",
       "  'OpenCV',\n",
       "  'Streamlit',\n",
       "  'Langchain',\n",
       "  'ReactJS',\n",
       "  'NextJS',\n",
       "  'FastAPI',\n",
       "  'Flask',\n",
       "  'AWS',\n",
       "  'Microsoft Azure',\n",
       "  'Linux'],\n",
       " 'domain_knowledge': ['Machine Learning',\n",
       "  'Generative AI',\n",
       "  'Natural Language Processing',\n",
       "  'Computer Vision',\n",
       "  'Data Structures and Algorithms',\n",
       "  'Statistics',\n",
       "  'Data Mining']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T04:23:40.015998Z",
     "iopub.status.busy": "2024-11-22T04:23:40.015610Z",
     "iopub.status.idle": "2024-11-22T04:23:40.021528Z",
     "shell.execute_reply": "2024-11-22T04:23:40.020265Z",
     "shell.execute_reply.started": "2024-11-22T04:23:40.015972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "jd_skil = [skill for skills in JD_skills.values() for skill in skills]\n",
    "resume_skil = [skill for skills in resume_skills.values() for skill in skills]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T04:23:44.706333Z",
     "iopub.status.busy": "2024-11-22T04:23:44.705970Z",
     "iopub.status.idle": "2024-11-22T04:23:44.713530Z",
     "shell.execute_reply": "2024-11-22T04:23:44.712342Z",
     "shell.execute_reply.started": "2024-11-22T04:23:44.706305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'PyTorch',\n",
       " 'LangChain',\n",
       " 'scikit-learn',\n",
       " 'HTML',\n",
       " 'CSS',\n",
       " 'Javascript',\n",
       " 'ReactJS',\n",
       " 'FastAPI',\n",
       " 'Pandas',\n",
       " 'Numpy',\n",
       " 'Keras',\n",
       " 'C',\n",
       " 'JAVA',\n",
       " 'C++',\n",
       " 'Oracle SQL',\n",
       " 'Machine Learning',\n",
       " 'Generative AI',\n",
       " 'Deep Learning',\n",
       " 'Natural Language Processing',\n",
       " 'Computer Vision',\n",
       " 'Neural networks',\n",
       " 'Clustering algorithms',\n",
       " 'Model aggregation',\n",
       " 'Template extraction',\n",
       " 'Feature matching',\n",
       " 'Fraud detection',\n",
       " 'OCR',\n",
       " 'ANN Model',\n",
       " 'Cardiovascular Disorders']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_skil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T08:42:00.266498Z",
     "iopub.status.busy": "2024-11-22T08:42:00.266141Z",
     "iopub.status.idle": "2024-11-22T08:42:16.580536Z",
     "shell.execute_reply": "2024-11-22T08:42:16.579252Z",
     "shell.execute_reply.started": "2024-11-22T08:42:00.266466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing JD skills...\n",
      "Found skill: Sql\n",
      "Found skill: Excel\n",
      "Found skill: Xml\n",
      "Found skill: Javascript\n",
      "Found skill: Etl\n",
      "Found skill: Spss\n",
      "Found skill: Sas\n",
      "Found skill: Data Mining\n",
      "No match found for: data analytics\n",
      "Found skill: Data Visualization\n",
      "Found skill: Statistics\n",
      "Found skill: Mathematics\n",
      "Found skill: Computer Science\n",
      "No match found for: economics\n",
      "\n",
      "Testing Resume skills...\n",
      "Found skill: Python\n",
      "Found skill: Java\n",
      "Found skill: C\n",
      "Found skill: C++\n",
      "Found skill: Html/Css\n",
      "Found skill: Javascript\n",
      "Found skill: Typescript\n",
      "Found skill: Sql\n",
      "Found skill: R\n",
      "Found skill: Pandas\n",
      "Found skill: Numpy\n",
      "Found skill: Matplotlib\n",
      "Found skill: Seaborn\n",
      "Found skill: Scikit-Learn\n",
      "Found skill: Tensorflow\n",
      "Found skill: Keras\n",
      "Found skill: Pytorch\n",
      "Found skill: Opencv\n",
      "Found skill: Streamlit\n",
      "Found skill: Langchain\n",
      "Found skill: Reactjs\n",
      "Found skill: Nextjs\n",
      "Found skill: Fastapi\n",
      "No match found for: flask\n",
      "Found skill: Aws\n",
      "Found skill: Microsoft Azure\n",
      "Found skill: Linux\n",
      "Found skill: Machine Learning\n",
      "Found skill: Generative Ai\n",
      "Found skill: Natural Language Processing\n",
      "Found skill: Computer Vision\n",
      "Found skill: Data Structures And Algorithms\n",
      "Found skill: Statistics\n",
      "Found skill: Data Mining\n",
      "\n",
      "Detailed Matching Metrics:\n",
      "Coverage Ratio: 0.67\n",
      "Average Distance Score: 0.16\n",
      "Matched Skills: 8/12\n",
      "Final Score: 0.47\n",
      "\n",
      "Match Analysis Summary:\n",
      "Final Match Score: 0.47\n",
      "Coverage of JD Skills: 66.7%\n",
      "Average Quality of Matches: 0.16\n",
      "Unmatched JD Skills: 4\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "\n",
    "def calculate_skill_match_score(jd_skills: List[str], resume_skills: List[str], graph) -> Tuple[float, Dict]:\n",
    "    \"\"\"\n",
    "    Calculate the skill match score between a job description and resume.\n",
    "    Returns both the final score and detailed metrics.\n",
    "    \n",
    "    The scoring considers:\n",
    "    1. Path distances between matched skills\n",
    "    2. Coverage ratio (how many JD skills were matched)\n",
    "    3. Relevance ratio (quality of the matches based on distance)\n",
    "    \"\"\"\n",
    "    print(\"Testing JD skills...\")\n",
    "    jd_skill_ids = get_skill_ids(jd_skills, graph)\n",
    "    print(\"\\nTesting Resume skills...\")\n",
    "    resume_skill_ids = get_skill_ids(resume_skills, graph)\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $jd_skill_ids AS jd_skill_id\n",
    "    UNWIND $resume_skill_ids AS resume_skill_id\n",
    "    MATCH (jd_skill) WHERE id(jd_skill) = jd_skill_id\n",
    "    MATCH (resume_skill) WHERE id(resume_skill) = resume_skill_id\n",
    "    MATCH path = shortestPath((resume_skill)-[*..10]-(jd_skill))\n",
    "    WHERE id(jd_skill) <> id(resume_skill)  // Exclude self-referential paths\n",
    "    RETURN \n",
    "        id(jd_skill) AS jd_skill,\n",
    "        id(resume_skill) AS resume_skill,\n",
    "        length(path) AS distance\n",
    "    \"\"\"\n",
    "\n",
    "    params = {'jd_skill_ids': jd_skill_ids, 'resume_skill_ids': resume_skill_ids}\n",
    "    try:\n",
    "        results = graph.query(query, params)\n",
    "    except Exception as e:\n",
    "        print(f\"Debug: Query execution failed with error: {e}\")\n",
    "        return 0.0, {\"error\": str(e)}\n",
    "\n",
    "    total_distance_score = 0\n",
    "    matched_jd_skills = set()\n",
    "    distance_scores = []  \n",
    "    \n",
    "    for result in results:\n",
    "        distance = result.get('distance')\n",
    "        if distance is None:\n",
    "            continue\n",
    "        \n",
    "        distance_score = 1.0 / (distance + 1)\n",
    "        total_distance_score += distance_score\n",
    "        distance_scores.append(distance_score)\n",
    "        \n",
    "        matched_jd_skills.add(result['jd_skill'])\n",
    "\n",
    "    total_jd_skills = len(jd_skill_ids)\n",
    "    matched_skills_count = len(matched_jd_skills)\n",
    "    coverage_ratio = matched_skills_count / total_jd_skills if total_jd_skills > 0 else 0\n",
    "\n",
    "    avg_distance_score = (sum(distance_scores) / len(distance_scores)) if distance_scores else 0\n",
    "    \n",
    "    coverage_weight = 0.6\n",
    "    relevance_weight = 1 - coverage_weight\n",
    "    \n",
    "    final_score = (coverage_weight * coverage_ratio) + (relevance_weight * avg_distance_score)\n",
    "\n",
    "    metrics = {\n",
    "        \"final_score\": final_score,\n",
    "        \"coverage_ratio\": coverage_ratio,\n",
    "        \"avg_distance_score\": avg_distance_score,\n",
    "        \"matched_skills_count\": matched_skills_count,\n",
    "        \"total_jd_skills\": total_jd_skills,\n",
    "        \"unmatched_skills_count\": total_jd_skills - matched_skills_count\n",
    "    }\n",
    "\n",
    "    print(f\"\\nDetailed Matching Metrics:\")\n",
    "    print(f\"Coverage Ratio: {coverage_ratio:.2f}\")\n",
    "    print(f\"Average Distance Score: {avg_distance_score:.2f}\")\n",
    "    print(f\"Matched Skills: {matched_skills_count}/{total_jd_skills}\")\n",
    "    print(f\"Final Score: {final_score:.2f}\")\n",
    "\n",
    "    return final_score, metrics\n",
    "\n",
    "def test_single_user_and_jd(graph, jd_skills: Dict[str, List[str]], resume_skills: Dict[str, List[str]]):\n",
    "    \"\"\"\n",
    "    Test matching with sample skills and print detailed metrics.\n",
    "    \"\"\"\n",
    "    jd_skills_flat = normalize_skills([skill for skills in jd_skills.values() for skill in skills])\n",
    "    resume_skills_flat = normalize_skills([skill for skills in resume_skills.values() for skill in skills])\n",
    "    \n",
    "    match_score, metrics = calculate_skill_match_score(jd_skills_flat, resume_skills_flat, graph)\n",
    "    \n",
    "    print(\"\\nMatch Analysis Summary:\")\n",
    "    print(f\"Final Match Score: {match_score:.2f}\")\n",
    "    print(f\"Coverage of JD Skills: {metrics['coverage_ratio']*100:.1f}%\")\n",
    "    print(f\"Average Quality of Matches: {metrics['avg_distance_score']:.2f}\")\n",
    "    print(f\"Unmatched JD Skills: {metrics['unmatched_skills_count']}\")\n",
    "\n",
    "def normalize_skills(skills: List[str]) -> List[str]:\n",
    "    return [skill.lower() for skill in skills]\n",
    "\n",
    "def get_skill_ids(skills: List[str], graph) -> List[int]:\n",
    "    skill_ids = []\n",
    "    query = \"\"\"\n",
    "    MATCH (n) \n",
    "    WHERE toLower(n.id) = $skill_name\n",
    "    RETURN id(n) AS node_id, n.id as found_name\n",
    "    \"\"\"\n",
    "    \n",
    "    for skill in skills:\n",
    "        try:\n",
    "            result = graph.query(query, {'skill_name': skill})\n",
    "            if result:\n",
    "                skill_ids.append(result[0]['node_id'])\n",
    "                print(f\"Found skill: {result[0]['found_name']}\")\n",
    "            else:\n",
    "                print(f\"No match found for: {skill}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Query error for {skill}: {e}\")\n",
    "    \n",
    "    return skill_ids\n",
    "\n",
    "\n",
    "test_single_user_and_jd(graph, JD_skills, resume_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multipe Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Resume_Name', 'Match_Score', 'Skills_Score', 'Graph_Score'])\n",
    "\n",
    "resume_folder = Path(\"/kaggle/input/resume/\")\n",
    "\n",
    "resume_data = []\n",
    "for resume_file in resume_folder.glob(\"*.pdf\"):\n",
    "    try:\n",
    "        resume_text = extract_resume_text(str(resume_file))\n",
    "        resume_skills = extract_skills(resume_text)\n",
    "        \n",
    "        node_names = get_all_node_names()\n",
    "        \n",
    "        llm = ChatGroq(model=\"llama-3.1-70b-versatile\", temperature=0.9)\n",
    "        relationships = llm.invoke([\n",
    "            (\"system\", \"You are a knowledge graph relationship specialist. Create clear, ONLY really close relationships between technical concepts.\"),\n",
    "            (\"human\", create_relationship_prompt(resume_skills, existing_knowledge=node_names))\n",
    "        ])\n",
    "        \n",
    "        # add to graph\n",
    "        text = relationships.content\n",
    "        documents = [Document(page_content=text)]\n",
    "        graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "        graph.add_graph_documents(graph_documents)\n",
    "        \n",
    "        resume_data.append({\n",
    "            'file_name': resume_file.name,\n",
    "            'skills': resume_skills\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {resume_file.name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T09:10:22.471241Z",
     "iopub.status.busy": "2024-11-22T09:10:22.470860Z",
     "iopub.status.idle": "2024-11-22T09:11:46.161189Z",
     "shell.execute_reply": "2024-11-22T09:11:46.159898Z",
     "shell.execute_reply.started": "2024-11-22T09:10:22.471211Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating scores...\n",
      "Testing JD skills...\n",
      "Found skill: Sql\n",
      "Found skill: Excel\n",
      "Found skill: Xml\n",
      "Found skill: Javascript\n",
      "Found skill: Etl\n",
      "Found skill: Spss\n",
      "Found skill: Sas\n",
      "Found skill: Data Mining\n",
      "No match found for: data analytics\n",
      "Found skill: Data Visualization\n",
      "Found skill: Statistics\n",
      "Found skill: Mathematics\n",
      "Found skill: Computer Science\n",
      "No match found for: economics\n",
      "\n",
      "Testing Resume skills...\n",
      "Found skill: Python\n",
      "Found skill: Html\n",
      "Found skill: Css\n",
      "Found skill: Sql\n",
      "Found skill: Postgresql\n",
      "Found skill: Oracle\n",
      "Found skill: Javascript\n",
      "Found skill: Angular\n",
      "Found skill: Django\n",
      "Found skill: Rest Apis\n",
      "Found skill: Graphql\n",
      "Found skill: Aws\n",
      "Found skill: Redshift\n",
      "Found skill: S3\n",
      "Found skill: Git\n",
      "Found skill: Selenium\n",
      "Found skill: D3.Js\n",
      "\n",
      "Detailed Matching Metrics:\n",
      "Coverage Ratio: 0.83\n",
      "Average Distance Score: 0.18\n",
      "Matched Skills: 10/12\n",
      "Final Score: 0.57\n",
      "\n",
      "Match Analysis Summary:\n",
      "Final Match Score: 0.57\n",
      "Coverage of JD Skills: 83.3%\n",
      "Average Quality of Matches: 0.18\n",
      "Unmatched JD Skills: 2\n",
      "Scored python-developer-resume-example.pdf: Match=0.57, Skills=0.83, Graph=0.18\n",
      "Testing JD skills...\n",
      "Found skill: Sql\n",
      "Found skill: Excel\n",
      "Found skill: Xml\n",
      "Found skill: Javascript\n",
      "Found skill: Etl\n",
      "Found skill: Spss\n",
      "Found skill: Sas\n",
      "Found skill: Data Mining\n",
      "No match found for: data analytics\n",
      "Found skill: Data Visualization\n",
      "Found skill: Statistics\n",
      "Found skill: Mathematics\n",
      "Found skill: Computer Science\n",
      "No match found for: economics\n",
      "\n",
      "Testing Resume skills...\n",
      "Found skill: Java\n",
      "Found skill: Sql\n",
      "Found skill: Soap\n",
      "Found skill: Springboot\n",
      "Found skill: Oracle\n",
      "Found skill: C++\n",
      "Found skill: Angular\n",
      "Found skill: Mongodb\n",
      "Found skill: Docker\n",
      "Found skill: Openshift\n",
      "No match found for: postgres\n",
      "\n",
      "Detailed Matching Metrics:\n",
      "Coverage Ratio: 0.83\n",
      "Average Distance Score: 0.18\n",
      "Matched Skills: 10/12\n",
      "Final Score: 0.57\n",
      "\n",
      "Match Analysis Summary:\n",
      "Final Match Score: 0.57\n",
      "Coverage of JD Skills: 83.3%\n",
      "Average Quality of Matches: 0.18\n",
      "Unmatched JD Skills: 2\n",
      "Scored java-programmer-resume-example.pdf: Match=0.57, Skills=0.83, Graph=0.18\n",
      "Testing JD skills...\n",
      "Found skill: Sql\n",
      "Found skill: Excel\n",
      "Found skill: Xml\n",
      "Found skill: Javascript\n",
      "Found skill: Etl\n",
      "Found skill: Spss\n",
      "Found skill: Sas\n",
      "Found skill: Data Mining\n",
      "No match found for: data analytics\n",
      "Found skill: Data Visualization\n",
      "Found skill: Statistics\n",
      "Found skill: Mathematics\n",
      "Found skill: Computer Science\n",
      "No match found for: economics\n",
      "\n",
      "Testing Resume skills...\n",
      "Found skill: Python\n",
      "Found skill: Javascript\n",
      "Found skill: Html5\n",
      "Found skill: Css\n",
      "Found skill: Django\n",
      "Found skill: Nodejs\n",
      "Found skill: Reactjs\n",
      "Found skill: Jquery\n",
      "Found skill: Unix\n",
      "Found skill: Git\n",
      "Found skill: Selenium\n",
      "Found skill: Sql\n",
      "Found skill: Postgresql\n",
      "Found skill: Mysql\n",
      "Found skill: Aws\n",
      "\n",
      "Detailed Matching Metrics:\n",
      "Coverage Ratio: 0.83\n",
      "Average Distance Score: 0.17\n",
      "Matched Skills: 10/12\n",
      "Final Score: 0.57\n",
      "\n",
      "Match Analysis Summary:\n",
      "Final Match Score: 0.57\n",
      "Coverage of JD Skills: 83.3%\n",
      "Average Quality of Matches: 0.17\n",
      "Unmatched JD Skills: 2\n",
      "Scored senior-programmer-resume-example.pdf: Match=0.57, Skills=0.83, Graph=0.17\n",
      "Testing JD skills...\n",
      "Found skill: Sql\n",
      "Found skill: Excel\n",
      "Found skill: Xml\n",
      "Found skill: Javascript\n",
      "Found skill: Etl\n",
      "Found skill: Spss\n",
      "Found skill: Sas\n",
      "Found skill: Data Mining\n",
      "No match found for: data analytics\n",
      "Found skill: Data Visualization\n",
      "Found skill: Statistics\n",
      "Found skill: Mathematics\n",
      "Found skill: Computer Science\n",
      "No match found for: economics\n",
      "\n",
      "Testing Resume skills...\n",
      "Found skill: Html\n",
      "Found skill: Css\n",
      "Found skill: Javascript\n",
      "Found skill: React.Js\n",
      "Found skill: Angular.Js\n",
      "Found skill: Vue.Js\n",
      "Found skill: Typescript\n",
      "Found skill: Git\n",
      "Found skill: Aws\n",
      "\n",
      "Detailed Matching Metrics:\n",
      "Coverage Ratio: 0.83\n",
      "Average Distance Score: 0.17\n",
      "Matched Skills: 10/12\n",
      "Final Score: 0.57\n",
      "\n",
      "Match Analysis Summary:\n",
      "Final Match Score: 0.57\n",
      "Coverage of JD Skills: 83.3%\n",
      "Average Quality of Matches: 0.17\n",
      "Unmatched JD Skills: 2\n",
      "Scored software-engineer-iii-front-end-resume-example.pdf: Match=0.57, Skills=0.83, Graph=0.17\n",
      "Testing JD skills...\n",
      "Found skill: Sql\n",
      "Found skill: Excel\n",
      "Found skill: Xml\n",
      "Found skill: Javascript\n",
      "Found skill: Etl\n",
      "Found skill: Spss\n",
      "Found skill: Sas\n",
      "Found skill: Data Mining\n",
      "No match found for: data analytics\n",
      "Found skill: Data Visualization\n",
      "Found skill: Statistics\n",
      "Found skill: Mathematics\n",
      "Found skill: Computer Science\n",
      "No match found for: economics\n",
      "\n",
      "Testing Resume skills...\n",
      "Found skill: Java\n",
      "Found skill: Spring\n",
      "Found skill: Hibernate\n",
      "Found skill: Sql\n",
      "Found skill: Aws\n",
      "Found skill: Azure\n",
      "Found skill: Itf+\n",
      "Found skill: A+\n",
      "Found skill: Cybersecurity\n",
      "Found skill: Project Management\n",
      "Found skill: Network Security\n",
      "Found skill: Software Engineering\n",
      "Found skill: Data Analysis\n",
      "Found skill: Statistics\n",
      "No match found for: it\n",
      "No match found for: cloud\n",
      "No match found for: automation\n",
      "Found skill: Firewall\n",
      "Found skill: Intrusion Detection\n",
      "Found skill: Process Control Network\n",
      "Found skill: Scada\n",
      "\n",
      "Detailed Matching Metrics:\n",
      "Coverage Ratio: 0.92\n",
      "Average Distance Score: 0.17\n",
      "Matched Skills: 11/12\n",
      "Final Score: 0.62\n",
      "\n",
      "Match Analysis Summary:\n",
      "Final Match Score: 0.62\n",
      "Coverage of JD Skills: 91.7%\n",
      "Average Quality of Matches: 0.17\n",
      "Unmatched JD Skills: 1\n",
      "Scored security-engineer-resume-example.pdf: Match=0.62, Skills=0.92, Graph=0.17\n",
      "Testing JD skills...\n",
      "Found skill: Sql\n",
      "Found skill: Excel\n",
      "Found skill: Xml\n",
      "Found skill: Javascript\n",
      "Found skill: Etl\n",
      "Found skill: Spss\n",
      "Found skill: Sas\n",
      "Found skill: Data Mining\n",
      "No match found for: data analytics\n",
      "Found skill: Data Visualization\n",
      "Found skill: Statistics\n",
      "Found skill: Mathematics\n",
      "Found skill: Computer Science\n",
      "No match found for: economics\n",
      "\n",
      "Testing Resume skills...\n",
      "Found skill: Python\n",
      "Found skill: Java\n",
      "Found skill: C\n",
      "Found skill: C++\n",
      "Found skill: Html/Css\n",
      "Found skill: Javascript\n",
      "Found skill: Typescript\n",
      "Found skill: Sql\n",
      "Found skill: R\n",
      "Found skill: Pandas\n",
      "Found skill: Numpy\n",
      "Found skill: Matplotlib\n",
      "Found skill: Seaborn\n",
      "Found skill: Scikit-Learn\n",
      "Found skill: Tensorflow\n",
      "Found skill: Keras\n",
      "Found skill: Pytorch\n",
      "Found skill: Opencv\n",
      "Found skill: Streamlit\n",
      "Found skill: Langchain\n",
      "Found skill: Reactjs\n",
      "Found skill: Nextjs\n",
      "Found skill: Fastapi\n",
      "Found skill: Flask\n",
      "Found skill: Aws\n",
      "Found skill: Microsoft Azure\n",
      "Found skill: Linux\n",
      "Found skill: Data Structures\n",
      "No match found for: algorithms\n",
      "Found skill: Generative Ai\n",
      "Found skill: Natural Language Processing\n",
      "Found skill: Machine Learning\n",
      "Found skill: Computer Vision\n",
      "Found skill: Neural Networks\n",
      "Found skill: Clustering Algorithms\n",
      "Found skill: Model Aggregation\n",
      "Found skill: Federated Learning\n",
      "Found skill: Artificial Intelligence\n",
      "Found skill: Statistics\n",
      "\n",
      "Detailed Matching Metrics:\n",
      "Coverage Ratio: 0.92\n",
      "Average Distance Score: 0.17\n",
      "Matched Skills: 11/12\n",
      "Final Score: 0.62\n",
      "\n",
      "Match Analysis Summary:\n",
      "Final Match Score: 0.62\n",
      "Coverage of JD Skills: 91.7%\n",
      "Average Quality of Matches: 0.17\n",
      "Unmatched JD Skills: 1\n",
      "Scored resume_v2.3.pdf: Match=0.62, Skills=0.92, Graph=0.17\n",
      "Testing JD skills...\n",
      "Found skill: Sql\n",
      "Found skill: Excel\n",
      "Found skill: Xml\n",
      "Found skill: Javascript\n",
      "Found skill: Etl\n",
      "Found skill: Spss\n",
      "Found skill: Sas\n",
      "Found skill: Data Mining\n",
      "No match found for: data analytics\n",
      "Found skill: Data Visualization\n",
      "Found skill: Statistics\n",
      "Found skill: Mathematics\n",
      "Found skill: Computer Science\n",
      "No match found for: economics\n",
      "\n",
      "Testing Resume skills...\n",
      "Found skill: Python\n",
      "No match found for: perl\n",
      "Found skill: Risc Cpu\n",
      "Found skill: Rtos\n",
      "Found skill: Jtag/Swd\n",
      "No match found for: c/c++\n",
      "Found skill: Qemu\n",
      "Found skill: Embedded Systems\n",
      "Found skill: Operating System Hardware\n",
      "Found skill: Computer Science\n",
      "\n",
      "Detailed Matching Metrics:\n",
      "Coverage Ratio: 0.83\n",
      "Average Distance Score: 0.20\n",
      "Matched Skills: 10/12\n",
      "Final Score: 0.58\n",
      "\n",
      "Match Analysis Summary:\n",
      "Final Match Score: 0.58\n",
      "Coverage of JD Skills: 83.3%\n",
      "Average Quality of Matches: 0.20\n",
      "Unmatched JD Skills: 2\n",
      "Scored embedded-software-engineer-resume-example.pdf: Match=0.58, Skills=0.83, Graph=0.20\n",
      "Testing JD skills...\n",
      "Found skill: Sql\n",
      "Found skill: Excel\n",
      "Found skill: Xml\n",
      "Found skill: Javascript\n",
      "Found skill: Etl\n",
      "Found skill: Spss\n",
      "Found skill: Sas\n",
      "Found skill: Data Mining\n",
      "No match found for: data analytics\n",
      "Found skill: Data Visualization\n",
      "Found skill: Statistics\n",
      "Found skill: Mathematics\n",
      "Found skill: Computer Science\n",
      "No match found for: economics\n",
      "\n",
      "Testing Resume skills...\n",
      "Found skill: Java\n",
      "Found skill: Python\n",
      "Found skill: Javascript\n",
      "Found skill: C++\n",
      "Found skill: Eclipse\n",
      "Found skill: Oracle Cloud Infrastructure\n",
      "Found skill: Oracle Database\n",
      "Found skill: Mongodb\n",
      "Found skill: Red Hat Openshift\n",
      "Found skill: Sql\n",
      "Found skill: Nosql\n",
      "\n",
      "Detailed Matching Metrics:\n",
      "Coverage Ratio: 0.83\n",
      "Average Distance Score: 0.18\n",
      "Matched Skills: 10/12\n",
      "Final Score: 0.57\n",
      "\n",
      "Match Analysis Summary:\n",
      "Final Match Score: 0.57\n",
      "Coverage of JD Skills: 83.3%\n",
      "Average Quality of Matches: 0.18\n",
      "Unmatched JD Skills: 2\n",
      "Scored principal-software-engineer-resume-example.pdf: Match=0.57, Skills=0.83, Graph=0.18\n",
      "\n",
      "Ranked Resumes:\n",
      "                                         Resume_Name  Match_Score  \\\n",
      "4               security-engineer-resume-example.pdf     0.618877   \n",
      "5                                    resume_v2.3.pdf     0.616097   \n",
      "6      embedded-software-engineer-resume-example.pdf     0.581044   \n",
      "1                 java-programmer-resume-example.pdf     0.571649   \n",
      "0                python-developer-resume-example.pdf     0.570210   \n",
      "7     principal-software-engineer-resume-example.pdf     0.570079   \n",
      "3  software-engineer-iii-front-end-resume-example...     0.566826   \n",
      "2               senior-programmer-resume-example.pdf     0.566526   \n",
      "\n",
      "   Skills_Score  Graph_Score  \n",
      "4      0.916667     0.172193  \n",
      "5      0.916667     0.165242  \n",
      "6      0.833333     0.202611  \n",
      "1      0.833333     0.179121  \n",
      "0      0.833333     0.175524  \n",
      "7      0.833333     0.175197  \n",
      "3      0.833333     0.167065  \n",
      "2      0.833333     0.166315  \n"
     ]
    }
   ],
   "source": [
    "def test_single_user_and_jd(graph, jd_skills: Dict[str, List[str]], resume_skills: Dict[str, List[str]]):\n",
    "    \"\"\"\n",
    "    Test matching with sample skills and return detailed metrics.\n",
    "    \"\"\"\n",
    "    # Flatten and normalize skills\n",
    "    jd_skills_flat = normalize_skills([skill for skills in jd_skills.values() for skill in skills])\n",
    "    resume_skills_flat = normalize_skills([skill for skills in resume_skills.values() for skill in skills])\n",
    "    \n",
    "    match_score, metrics = calculate_skill_match_score(jd_skills_flat, resume_skills_flat, graph)\n",
    "    \n",
    "    print(\"\\nMatch Analysis Summary:\")\n",
    "    print(f\"Final Match Score: {match_score:.2f}\")\n",
    "    print(f\"Coverage of JD Skills: {metrics['coverage_ratio']*100:.1f}%\")\n",
    "    print(f\"Average Quality of Matches: {metrics['avg_distance_score']:.2f}\")\n",
    "    print(f\"Unmatched JD Skills: {metrics['unmatched_skills_count']}\")\n",
    "    \n",
    "    return (\n",
    "        match_score,\n",
    "        metrics['coverage_ratio'],\n",
    "        metrics['avg_distance_score']\n",
    "    )\n",
    "\n",
    "print(\"\\nCalculating scores...\")\n",
    "for resume in resume_data:\n",
    "    try:\n",
    "        scores = test_single_user_and_jd(graph, JD_skills, resume['skills'])\n",
    "        match_score, skills_score, graph_score = scores\n",
    "        \n",
    "        results_df.loc[len(results_df)] = {\n",
    "            'Resume_Name': resume['file_name'],\n",
    "            'Match_Score': match_score,\n",
    "            'Skills_Score': skills_score,\n",
    "            'Graph_Score': graph_score\n",
    "        }\n",
    "        print(f\"Scored {resume['file_name']}: Match={match_score:.2f}, Skills={skills_score:.2f}, Graph={graph_score:.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in scoring {resume['file_name']}: {str(e)}\")\n",
    "\n",
    "if not results_df.empty:\n",
    "    results_df_sorted = results_df.sort_values(by='Match_Score', ascending=False)\n",
    "    print(\"\\nRanked Resumes:\")\n",
    "    print(results_df_sorted)\n",
    "    results_df_sorted.to_csv('resume_rankings.csv', index=False)\n",
    "else:\n",
    "    print(\"\\nNo results to display - check the errors above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full FLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Create Main Knowledge Graph\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Setup Neo4j connection\n",
    "os.environ[\"NEO4J_URI\"] = \"neo4j+s://80e9be90.databases.neo4j.io\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\" \n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"P2jyV6JZdfGh1K4MsVDwrWz4GuboXH7Uc4JKPaElzfE\"\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "graph = Neo4jGraph(refresh_schema=False)\n",
    "llm = ChatGroq(model=\"llama-3.1-70b-versatile\", temperature=0)\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "\n",
    "# Load and transform knowledge base\n",
    "with open(\"/kaggle/input/dl-project-dataset-interview/Knowledge INPUT.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "documents = [Document(page_content=text)]\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "#graph.add_graph_documents(graph_documents)\n",
    "\n",
    "# 2. Extract Skills from Job Description\n",
    "text = \"\"\"[Your JD text here]\"\"\"  # Replace with actual JD text\n",
    "JD_skills = extract_skills(text)\n",
    "\n",
    "# 3. Extract Skills from Resume\n",
    "resume_file = \"/kaggle/input/resume/resume_v1.docx\"\n",
    "resume_text = extract_resume_text(resume_file)\n",
    "resume_skills = extract_skills(resume_text)\n",
    "\n",
    "# 4. Create Relationships and Update Knowledge Graph\n",
    "# Get existing nodes\n",
    "node_names = get_all_node_names()\n",
    "\n",
    "# Generate relationships text\n",
    "llm = ChatGroq(model=\"llama-3.1-70b-versatile\", temperature=0.9)\n",
    "relationships = llm.invoke([\n",
    "    (\"system\", \"You are a knowledge graph relationship specialist. Create clear, ONLY really close relationships between technical concepts.\"),\n",
    "    (\"human\", create_relationship_prompt(resume_skills, existing_knowledge=node_names))\n",
    "])\n",
    "\n",
    "# Transform and add new relationships\n",
    "text = relationships.content\n",
    "documents = [Document(page_content=text)]\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "graph.add_graph_documents(graph_documents)\n",
    "\n",
    "\n",
    "relationships = llm.invoke([\n",
    "    (\"system\", \"You are a knowledge graph relationship specialist. Create clear, ONLY really close relationships between technical concepts.\"),\n",
    "    (\"human\", create_relationship_prompt(JD_skills, existing_knowledge=node_names))\n",
    "])\n",
    "\n",
    "# Transform and add new relationships\n",
    "text = relationships.content\n",
    "documents = [Document(page_content=text)]\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "graph.add_graph_documents(graph_documents)\n",
    "\n",
    "# 5. Calculate Match Score\n",
    "test_single_user_and_jd(graph, JD_skills, resume_skills)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10165663,
     "datasetId": 6087564,
     "sourceId": 9908200,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10246469,
     "datasetId": 6087735,
     "sourceId": 9980525,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
